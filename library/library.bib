@article{Aron2007a,
abstract = {The ability to stop motor responses depends critically on the right inferior frontal cortex (IFC) and also engages a midbrain region consistent with the subthalamic nucleus (STN). Here we used diffusion-weighted imaging (DWI) tractography to show that the IFC and the STN region are connected via a white matter tract, which could underlie a "hyperdirect" pathway for basal ganglia control. Using a novel method of "triangulation" analysis of tractography data, we also found that both the IFC and the STN region are connected with the presupplementary motor area (preSMA). We hypothesized that the preSMA could play a conflict detection/resolution role within a network between the preSMA, the IFC, and the STN region. A second experiment tested this idea with functional magnetic resonance imaging (fMRI) using a conditional stop-signal paradigm, enabling examination of behavioral and neural signatures of conflict-induced slowing. The preSMA, IFC, and STN region were significantly activated the greater the conflict-induced slowing. Activation corresponded strongly with spatial foci predicted by the DWI tract analysis, as well as with foci activated by complete response inhibition. The results illustrate how tractography can reveal connections that are verifiable with fMRI. The results also demonstrate a three-way functional-anatomical network in the right hemisphere that could either brake or completely stop responses.},
author = {Aron, Adam R and Behrens, Tim E and Smith, Steve and Frank, Michael J and Poldrack, Russell A},
doi = {10.1523/JNEUROSCI.0519-07.2007},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aron et al. - 2007 - Triangulating a cognitive control network using diffusion-weighted magnetic resonance imaging (MRI) and function(2).pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {Adult,Brain Mapping,Brain Mapping: methods,Cognition,Cognition: physiology,Diffusion Magnetic Resonance Imaging,Diffusion Magnetic Resonance Imaging: methods,Female,Humans,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Male,Nerve Net,Nerve Net: physiology,Photic Stimulation,Photic Stimulation: methods,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology},
month = {apr},
number = {14},
pages = {3743--3752},
pmid = {17409238},
title = {{Triangulating a Cognitive Control Network Using Diffusion-Weighted Magnetic Resonance Imaging (MRI) and Functional MRI}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0519-07.2007},
volume = {27},
year = {2007}
}
@article{Aron2003,
abstract = {The precise localization of executive functions such as response inhibition within the prefrontal cortex (PFC), although theoretically crucial, has proven to be controversial and difficult1. Functional neuroimaging has contributed importantly to this debate1, 2, 3, 4, 5, 6, 7, but as human cortical lesions are seldom discrete, the literature still lacks definitive neuropsychological evidence that a specific region is necessary for task performance. We overcame this limitation by using a new observer-independent method to relate the degree of damage within a specific prefrontal region to performance on a stop-signal task that is sensitive to the neurodevelopmental aspects of stopping behavior2 and to attention-deficit/hyperactivity disorder (ADHD) as well as its amelioration by methylphenidate5, 8.},
author = {Aron, Adam R and Fletcher, Paul C and Bullmore, Ed T and Sahakian, Barbara J and Robbins, Trevor W},
doi = {10.1038/nn1003},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Post error slowing/Aron et al. - 2003 - Stop-signal inhibition disrupted by damage to right inferior frontal gyrus in humans.pdf:pdf},
isbn = {1097-6256},
issn = {10976256},
journal = {Nature Neuroscience},
number = {2},
pages = {115--116},
pmid = {12536210},
title = {{Stop-signal inhibition disrupted by damage to right inferior frontal gyrus in humans}},
url = {http://www.nature.com/doifinder/10.1038/nn1003},
volume = {6},
year = {2003}
}
@article{Aron2014b,
abstract = {In our TICS Review in 2004, we proposed that a sector of the right inferior frontal cortex (rIFC) in humans is critical for inhibiting response tendencies. Here we survey new evidence, discuss ongoing controversies, and provide an updated theory. We propose that the rIFC (along with one or more fronto-basal-ganglia networks) is best characterized as a brake. This brake can be turned on in different modes (totally, to outright suppress a response; or partially, to pause), and in different contexts (externally, by stop or salient signals; or internally, by goals). We affirm inhibition as a central component of executive control that relies upon the rIFC and associated networks, and explain why rIFC disruption could generally underpin response control disorders. ?? 2014 Elsevier Ltd.},
author = {Aron, Adam R and Robbins, Trevor W and Poldrack, Russell A},
doi = {10.1016/j.tics.2013.12.003},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aron, Robbins, Poldrack - 2014 - Inhibition and the right inferior frontal cortex One decade on.pdf:pdf},
isbn = {1364-6613},
issn = {1879307X},
journal = {Trends in Cognitive Sciences},
keywords = {Braking,Impulse control,Prefrontal cortex,Stopping},
number = {4},
pages = {177--185},
pmid = {24440116},
title = {{Inhibition and the right inferior frontal cortex: One decade on}},
url = {http://dx.doi.org/10.1016/j.tics.2013.12.003},
volume = {18},
year = {2014}
}
@article{Boekel2017,
abstract = {Recent efforts to replicate structural brain-behavior correlations have called into question the replicability of structural brain measures used in cognitive neuroscience. Here, we report an evaluation of test-retest reliability of diffusion tensor imaging (DTI) measures, including fractional anisotropy, mean diffusivity, axial diffusivity, and radial diffusivity, in several white matter tracts previously shown to be involved in cognitive control. In a data set consisting of 34 healthy participants scanned twice on a single day, we observe overall stability of DTI measures. This stability remained in a subset of participants who were also scanned a third time on the same day as well as in a 2-week follow-up session. We conclude that DTI measures in these tracts show relative stability, and that alternative explanations for the recent failures of replication must be considered.},
author = {Boekel, Wouter and Forstmann, Birte U and Keuken, Max C},
doi = {10.1111/psyp.12769},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Anatomy and Function/Boekel, Forstmann, Keuken - 2017 - A test-retest reliability analysis of diffusion measures of white matter tracts relevant for cognitiv.pdf:pdf},
issn = {14698986},
journal = {Psychophysiology},
keywords = {Cognitive control,DTI,Diffusion tensor imaging,Test-retest reliability},
number = {1},
pages = {24--33},
pmid = {28000260},
title = {{A test-retest reliability analysis of diffusion measures of white matter tracts relevant for cognitive control}},
volume = {54},
year = {2017}
}
@article{Bogacz2010,
abstract = {In many situations, decision makers need to negotiate between the competing demands of response speed and response accuracy, a dilemma generally known as the speed-accuracy tradeoff (SAT). Despite the ubiquity of SAT, the question of how neural decision circuits implement SAT has received little attention up until a year ago. We review recent studies that show SAT is modulated in association and pre-motor areas rather than in sensory or primary motor areas. Furthermore, the studies suggest that emphasis on response speed increases the baseline firing rate of cortical integrator neurons. We also review current theories on how and where in the brain the SAT is controlled, and we end by proposing research directions that could distinguish between these theories. ?? 2009 Elsevier Ltd. All rights reserved.},
author = {Bogacz, Rafal and Wagenmakers, Eric-Jan and Forstmann, Birte U and Nieuwenhuis, Sander},
doi = {10.1016/j.tins.2009.09.002},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bogacz et al. - 2010 - The neural basis of the speed-accuracy tradeoff.pdf:pdf},
isbn = {1878-108X (Electronic)$\backslash$n0166-2236 (Linking)},
issn = {01662236},
journal = {Trends in Neurosciences},
number = {1},
pages = {10--16},
pmid = {19819033},
title = {{The neural basis of the speed-accuracy tradeoff}},
volume = {33},
year = {2010}
}
@article{Botvinick2001,
abstract = {A neglected question regarding cognitive control is how control processes might detect situations calling for their involvement. The authors propose here that the demand for control may be evaluated in part by monitoring for conflicts in information processing. This hypothesis is supported by data concerning the anterior cingulate cortex, a brain area involved in cognitive control, which also appears to respond to the occurrence of conflict. The present article reports two computational modeling studies, serving to articulate the conflict monitoring hypothesis and examine its implications. The first study tests the sufficiency of the hypothesis to account for brain activation data, applying a measure of conflict to existing models of tasks shown to engage the anterior cingulate. The second study implements a feedback loop connecting conflict monitoring to cognitive control, using this to simulate a number of important behavioral phenomena.},
author = {Botvinick, Matthew M and Braver, Todd S and Barch, Deanna M and Carter, Cameron S and Cohen, Jonathan D},
doi = {10.1037/0033-295X.108.3.624},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Botvinick et al. - 2001 - Conflict monitoring and cognitive control.pdf:pdf},
isbn = {0033-295X},
issn = {0033-295X},
journal = {Psychological review},
number = {3},
pages = {624--652},
pmid = {11488380},
title = {{Conflict monitoring and cognitive control.}},
volume = {108},
year = {2001}
}
@article{Botvinick2014,
author = {Botvinick, Matthew M and Weinstein, Ari},
doi = {10.1098/rstb.2013.0480},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Botvinick, Weinstein - 2014 - Model-based hierarchical reinforcement learning and human action control.pdf:pdf},
journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
keywords = {behaviour,cognition,computational biology},
number = {1655},
pages = {20130480},
title = {{Model-based hierarchical reinforcement learning and human action control}},
volume = {369},
year = {2014}
}
@article{Braver2012,
abstract = {A core component of cognitive control - the ability to regulate thoughts and actions in accordance with internally represented behavioral goals - might be its intrinsic variability. In this article, I describe the dual mechanisms of control (DMC) framework, which postulates that this variability might arise from qualitative distinctions in temporal dynamics between proactive and reactive modes of control. Proactive control reflects the sustained and anticipatory maintenance of goal-relevant information within lateral prefrontal cortex (PFC) to enable optimal cognitive performance, whereas reactive control reflects transient stimulus-driven goal reactivation that recruits lateral PFC (plus a wider brain network) based on interference demands or episodic associations. I summarize recent research that demonstrates how the DMC framework provides a coherent explanation of three sources of cognitive control variation - intra-individual, inter-individual and between-groups - in terms of proactive versus reactive control biases. ?? 2011 Elsevier Ltd.},
author = {Braver, Todd S},
doi = {10.1016/j.tics.2011.12.010},
isbn = {1364-6613},
issn = {13646613},
journal = {Trends in Cognitive Sciences},
number = {2},
pages = {106--113},
pmid = {22245618},
title = {{The variable nature of cognitive control: A dual mechanisms framework}},
url = {http://dx.doi.org/10.1016/j.tics.2011.12.010},
volume = {16},
year = {2012}
}
@article{Cavanagh2010a,
abstract = {Investigations into action monitoring have consistently detailed a frontocentral voltage deflection in the event-related potential (ERP) following the presentation of negatively valenced feedback, sometimes termed the feedback-related negativity (FRN). The FRN has been proposed to reflect a neural response to prediction errors during reinforcement learning, yet the single-trial relationship between neural activity and the quanta of expectation violation remains untested. Although ERP methods are not well suited to single-trial analyses, the FRN has been associated with theta band oscillatory perturbations in the medial prefrontal cortex. Mediofrontal theta oscillations have been previously associated with expectation violation and behavioral adaptation and are well suited to single-trial analysis. Here, we recorded EEG activity during a probabilistic reinforcement learning task and fit the performance data to an abstract computational model (Q-learning) for calculation of single-trial reward prediction errors. Single-trial theta oscillatory activities following feedback were investigated within the context of expectation (prediction error) and adaptation (subsequent reaction time change). Results indicate that interactive medial and lateral frontal theta activities reflect the degree of negative and positive reward prediction error in the service of behavioral adaptation. These different brain areas use prediction error calculations for different behavioral adaptations, with medial frontal theta reflecting the utilization of prediction errors for reaction time slowing (specifically following errors), but lateral frontal theta reflecting prediction errors leading to working memory-related reaction time speeding for the correct choice.},
author = {Cavanagh, James F and Frank, Michael J and Klein, Theresa J and Allen, John J B},
doi = {10.1016/j.neuroimage.2009.11.080},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cavanagh et al. - 2010 - Frontal theta links prediction errors to behavioral adaptation in reinforcement learning(2).pdf:pdf;:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cavanagh et al. - 2010 - Frontal theta links prediction errors to behavioral adaptation in reinforcement learning(3).pdf:pdf},
issn = {1095-9572},
journal = {NeuroImage},
keywords = {Adaptation,Adolescent,Adult,Decision Making,Decision Making: physiology,Female,Frontal Lobe,Frontal Lobe: physiology,Humans,Male,Neural Pathways,Neural Pathways: physiology,Physiological,Physiological: physiology,Reinforcement (Psychology),Reward,Theta Rhythm,Theta Rhythm: methods,Young Adult},
month = {feb},
number = {4},
pages = {3198--209},
pmid = {19969093},
publisher = {Elsevier Inc.},
title = {{Frontal theta links prediction errors to behavioral adaptation in reinforcement learning.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2818688{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {49},
year = {2010}
}
@article{Cavanagh2014a,
abstract = {pFC is proposed to implement cognitive control via directed “top–down” influence over behavior. But how is this feat achieved? The virtue of such a descriptive model is contingent on a mechanistic understanding of how motor execution is altered in specific circumstances. In this report, we provide evidence that the well-known phenomenon of slowed RTs following mistakes (post-error slowing) is directly influenced by the degree of subthalamic nucleus (STN) activity. The STN is proposed to act as a brake on motor execution following conflict or errors, buying time so a more cautious response can be made on the next trial. STN local field potentials from nine Parkinson disease patients undergoing deep brain stimulation surgery were recorded while they performed a response conflict task. In a 2.5- to 5-Hz frequency range previously associated with conflict and error processing, the degree phase consistency preceding the response was associated with increasingly slower RTs specifically following errors. These f...},
archivePrefix = {arXiv},
arxivId = {1511.04103},
author = {Cavanagh, James F and Sanguinetti, Joseph L and Allen, John J B and Sherman, Scott J and Frank, Michael J},
doi = {10.1162/jocn_a_00659},
eprint = {1511.04103},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cavanagh et al. - 2013 - The Subthalamic Nucleus Contributes to Post-error Slowing.pdf:pdf},
isbn = {1530-8898 (Electronic)$\backslash$r0898-929X (Linking)},
issn = {0898-929X},
journal = {Journal of Cognitive Neuroscience},
number = {11},
pages = {2637--2644},
pmid = {24800632},
title = {{The Subthalamic Nucleus Contributes to Post-error Slowing}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/jocn{\_}a{\_}00659},
volume = {26},
year = {2014}
}
@article{Cavanagh2011b,
abstract = {It takes effort and time to tame one's impulses. Although medial prefrontal cortex (mPFC) is broadly implicated in effortful control over behavior, the subthalamic nucleus (STN) is specifically thought to contribute by acting as a brake on cortico-striatal function during decision conflict, buying time until the right decision can be made. Using the drift diffusion model of decision making, we found that trial-to-trial increases in mPFC activity (EEG theta power, 4-8 Hz) were related to an increased threshold for evidence accumulation (decision threshold) as a function of conflict. Deep brain stimulation of the STN in individuals with Parkinson's disease reversed this relationship, resulting in impulsive choice. In addition, intracranial recordings of the STN area revealed increased activity (2.5-5 Hz) during these same high-conflict decisions. Activity in these slow frequency bands may reflect a neural substrate for cortico-basal ganglia communication regulating decision processes.},
author = {Cavanagh, James F and Wiecki, Thomas V and Cohen, Michael X and Figueroa, Christina M and Samanta, Johan and Sherman, Scott J and Frank, Michael J},
doi = {10.1038/nn.2925},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cavanagh et al. - 2011 - Subthalamic nucleus stimulation reverses mediofrontal influence over decision threshold.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$n1097-6256 (Linking)},
issn = {1546-1726},
journal = {Nature neuroscience},
keywords = {Adult,Age Factors,Aged,Bayes Theorem,Brain Mapping,Cognition Disorders,Cognition Disorders: etiology,Cognition Disorders: pathology,Cognition Disorders: therapy,Cues,Decision Making,Decision Making: physiology,Deep Brain Stimulation,Deep Brain Stimulation: methods,Delta Rhythm,Delta Rhythm: physiology,Differential Threshold,Differential Threshold: physiology,Electroencephalography,Female,Fourier Analysis,Humans,Male,Markov Chains,Middle Aged,Models,Neuropsychological Tests,Parkinson Disease,Parkinson Disease: complications,Prefrontal Cortex,Prefrontal Cortex: physiopathology,Reaction Time,Regression Analysis,Subthalamic Nucleus,Subthalamic Nucleus: physiology,Theoretical,Theta Rhythm,Theta Rhythm: physiology},
number = {11},
pages = {1462--7},
pmid = {21946325},
title = {{Subthalamic nucleus stimulation reverses mediofrontal influence over decision threshold.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3394226{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {14},
year = {2011}
}
@article{Chambers2006,
abstract = {In the course of daily living, humans frequently encounter situations in which a motor activity, once initiated, becomes unnecessary or inappropriate. Under such circumstances, the ability to inhibit motor responses can be of vital importance. Although the nature of response inhibition has been studied in psychology for several decades, its neural basis remains unclear. Using transcranial magnetic stimulation, we found that temporary deactivation of the pars opercularis in the right inferior frontal gyrus selectively impairs the ability to stop an initiated action. Critically, deactivation of the same region did not affect the ability to execute responses, nor did it influence physiological arousal. These findings confirm and extend recent reports that the inferior frontal gyrus is vital for mediating response inhibition.},
author = {Chambers, Christopher D and Bellgrove, Mark A and Stokes, Mark G and Henderson, Tracy R and Garavan, Hugh and Robertson, Ian H and Morris, Adam P and Mattingley, Jason B},
doi = {10.1162/jocn.2006.18.3.444},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Cognitive Control/Chambers et al. - 2006 - Executive “Brake Failure” following Deactivation of Human Frontal Lobe.pdf:pdf},
isbn = {0898-929X (Print)$\backslash$r0898-929X (Linking)},
issn = {0898-929X},
journal = {Journal of Cognitive Neuroscience},
number = {3},
pages = {444--455},
pmid = {16513008},
title = {{Executive “Brake Failure” following Deactivation of Human Frontal Lobe}},
url = {http://www.mitpressjournals.org/doi/10.1162/jocn.2006.18.3.444},
volume = {18},
year = {2006}
}
@article{Chase2015,
author = {Chase, Henry W and Kumar, Poornima and Eickhoff, Simon B and Dombrovski, Alexandre Y},
doi = {10.3758/s13415-015-0338-7},
issn = {1530-7026},
journal = {Cognitive, Affective, {\&} Behavioral Neuroscience},
keywords = {expected value,learning,meta analysis,prediction error,reinforcement},
number = {2},
pages = {435--59},
title = {{Reinforcement learning models and their neural correlates: An activation likelihood estimation meta-analysis}},
url = {http://link.springer.com/10.3758/s13415-015-0338-7},
volume = {15},
year = {2015}
}
@article{Cohen2007,
abstract = {Many large and small decisions we make in our daily lives-which ice cream to choose, what research projects to pursue, which partner to marry-require an exploration of alternatives before committing to and exploiting the benefits of a particular choice. Furthermore, many decisions require re-evaluation, and further exploration of alternatives, in the face of changing needs or circumstances. That is, often our decisions depend on a higher level choice: whether to exploit well known but possibly suboptimal alternatives or to explore risky but potentially more profitable ones. How adaptive agents choose between exploitation and exploration remains an important and open question that has received relatively limited attention in the behavioural and brain sciences. The choice could depend on a number of factors, including the familiarity of the environment, how quickly the environment is likely to change and the relative value of exploiting known sources of reward versus the cost of reducing uncertainty through exploration. There is no known generally optimal solution to the exploration versus exploitation problem, and a solution to the general case may indeed not be possible. However, there have been formal analyses of the optimal policy under constrained circumstances. There have also been specific suggestions of how humans and animals may respond to this problem under particular experimental conditions as well as proposals about the brain mechanisms involved. Here, we provide a brief review of this work, discuss how exploration and exploitation may be mediated in the brain and highlight some promising future directions for research.},
author = {Cohen, Jonathan D and McClure, Samuel M and Yu, Angela J},
doi = {10.1098/rstb.2007.2098},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen, McClure, Yu - 2007 - Should I stay or should I go How the human brain manages the trade-off between exploitation and explorati(2).pdf:pdf;:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cohen, McClure, Yu - 2007 - Should I stay or should I go How the human brain manages the trade-off between exploitation and explorati(3).pdf:pdf},
issn = {0962-8436},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Brain,Brain: physiology,Decision Making,Decision Making: physiology,Exploratory Behavior,Exploratory Behavior: physiology,Humans},
month = {may},
number = {1481},
pages = {933--42},
pmid = {17395573},
title = {{Should I stay or should I go? How the human brain manages the trade-off between exploitation and exploration.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2430007{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {362},
year = {2007}
}
@article{Danielmeier2011,
abstract = {As Seneca the Younger put it, "To err is human, but to persist is diabolical." To prevent repetition of errors, human performance monitoring often triggers adaptations such as general slowing and/or attentional focusing. The posterior medial frontal cortex (pMFC) is assumed to monitor performance problems and to interact with other brain areas that implement the necessary adaptations. Whereas previous research showed interactions between pMFC and lateral-prefrontal regions, here we demonstrate that upon the occurrence of errors the pMFC selectively interacts with perceptual and motor regions and thereby drives attentional focusing toward task-relevant information and induces motor adaptation observed as post-error slowing. Functional magnetic resonance imaging data from an interference task reveal that error-related pMFC activity predicts the following: (1) subsequent activity enhancement in perceptual areas encoding task-relevant stimulus features; (2) activity suppression in perceptual areas encoding distracting stimulus features; and (3) post-error slowing-related activity decrease in the motor system. Additionally, diffusion-weighted imaging revealed a correlation of individual post-error slowing and white matter integrity beneath pMFC regions that are connected to the motor inhibition system, encompassing right inferior frontal gyrus and subthalamic nucleus. Thus, disturbances in task performance are remedied by functional interactions of the pMFC with multiple task-related brain regions beyond prefrontal cortex that result in a broad repertoire of adaptive processes at perceptual as well as motor levels.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Danielmeier, Claudia and Eichele, Tom and Forstmann, Birte U and Tittgemeyer, Marc and Ullsperger, Markus},
doi = {10.1523/JNEUROSCI.4299-10.2011},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Danielmeier et al. - 2011 - Posterior medial frontal cortex activity predicts post-error adaptations in task-related visual and motor ar.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$n0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {Adaptation,Adult,Attention,Female,Frontal Lobe,Frontal Lobe: physiology,Humans,Magnetic Resonance Imaging,Male,Motion Perception,Neuropsychological Tests,Prefrontal Cortex,Prefrontal Cortex: physiology,Psychological,Psychomotor Performance,Subthalamic Nucleus,Subthalamic Nucleus: physiology,Visual Perception},
month = {mar},
number = {5},
pages = {1780--1789},
pmid = {21289188},
title = {{Posterior Medial Frontal Cortex Activity Predicts Post-Error Adaptations in Task-Related Visual and Motor Areas}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4299-10.2011},
volume = {31},
year = {2011}
}
@article{Danielmeier2011b,
abstract = {When our brain detects an error, this process changes how we react on ensuing trials. People show post-error adaptations, potentially to improve their performance in the near future. At least three types of behavioral post-error adjustments have been observed. These are post-error slowing (PES), post-error reduction of interference, and post-error improvement in accuracy (PIA). Apart from these behavioral changes, post-error adaptations have also been observed on a neuronal level with functional magnetic resonance imaging and electroencephalography. Neuronal post-error adaptations comprise activity increase in task-relevant brain areas, activity decrease in distracter-encoding brain areas, activity modulations in the motor system, and mid-frontal theta power increases. Here, we review the current literature with respect to these post-error adjustments, discuss under which circumstances these adjustments can be observed, and whether the different types of adjustments are linked to each other. We also evaluate different approaches for explaining the functional role of PES. In addition, we report reanalyzed and follow-up data from a flanker task and a moving dots interference task showing (1) that PES and PIA are not necessarily correlated, (2) that PES depends on the response-stimulus interval, and (3) that PES is reliable on a within-subject level over periods as long as several months.},
annote = {From Duplicate 1 ( Post-error adjustments. - Danielmeier, Claudia; Ullsperger, Markus )
},
author = {Danielmeier, Claudia and Ullsperger, Markus},
doi = {10.3389/fpsyg.2011.00233},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Danielmeier, Ullsperger - 2011 - Post-error adjustments(2).pdf:pdf;:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Danielmeier, Ullsperger - 2011 - Post-error adjustments(3).pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in psychology},
keywords = {an error,cognitive,control,for a brief moment,inhibition,or at least we,orienting response,post-error improvement in accuracy,post-error reduction of interf,post-error reduction of interference,post-error slowing,posterior medial frontal cortex,slow,stop our current movement,we have just committed,we often,when we realize that},
pmid = {21954390},
title = {{Post-error adjustments.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3173829{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {2},
year = {2011}
}
@article{Daw2011,
author = {Daw, Nathaniel D},
doi = {10.1093/acprof:oso/9780199600434.003.0001},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Daw - 2009 - Trial-by-trial data analysis using computational models(2).pdf:pdf},
journal = {Decision making, affect, and learning: Attention and Performance XXIII},
pages = {3--38},
title = {{Trial-by-trial data analysis using computational models}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=lAHKGtbeunwC{\&}oi=fnd{\&}pg=PA3{\&}ots=Jdqknuepm2{\&}sig=ByHAZy{\_}qF1rouJiEPBZl72Pe9Z0},
volume = {23},
year = {2011}
}
@article{Dickerson2009,
abstract = {Alzheimer's disease (AD) is associated with neurodegeneration in vulnerable limbic and heteromodal regions of the cerebral cortex, detectable in vivo using magnetic resonance imaging. It is not clear whether abnormalities of cortical anatomy in AD can be reliably measured across different subject samples, how closely they track symptoms, and whether they are detectable prior to symptoms. An exploratory map of cortical thinning in mild AD was used to define regions of interest that were applied in a hypothesis-driven fashion to other subject samples. Results demonstrate a reliably quantifiable in vivo signature of abnormal cortical anatomy in AD, which parallels known regional vulnerability to AD neuropathology. Thinning in vulnerable cortical regions relates to symptom severity even in the earliest stages of clinical symptoms. Furthermore, subtle thinning is present in asymptomatic older controls with brain amyloid binding as detected with amyloid imaging. The reliability and clinical validity of AD-related cortical thinning suggests potential utility as an imaging biomarker. This "disease signature" approach to cortical morphometry, in which disease effects are mapped across the cortical mantle and then used to define ROIs for hypothesis-driven analyses, may provide a powerful methodological framework for studies of neuropsychiatric diseases.},
author = {Dickerson, Bradford C and Bakkour, Akram and Salat, David H and Feczko, Eric and Pacheco, Jenni and Greve, Douglas N and Grodstein, Fran and Wright, Christopher I and Blacker, Deborah and Rosas, H. Diana and Sperling, Reisa A and Atri, Alireza and Growdon, John H and Hyman, Bradley T and Morris, John C and Fischl, Bruce and Buckner, Randy L},
doi = {10.1093/cercor/bhn113},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Anatomy and Function/Dickerson et al. - 2009 - The cortical signature of Alzheimer's disease Regionally specific cortical thinning relates to symptom severit.pdf:pdf},
isbn = {1460-2199 (Electronic)$\backslash$n1047-3211 (Linking)},
issn = {10473211},
journal = {Cerebral Cortex},
keywords = {Alzheimer's disease,Cerebral cortex,Magnetic resonance imaging,Medial temporal lobe,Parietal cortex},
number = {3},
pages = {497--510},
pmid = {18632739},
title = {{The cortical signature of Alzheimer's disease: Regionally specific cortical thinning relates to symptom severity in very mild to mild AD dementia and is detectable in asymptomatic amyloid-positive individuals}},
volume = {19},
year = {2009}
}
@article{Dickerson2012,
abstract = {Objective:$\backslash$nNew preclinical Alzheimer disease (AD) diagnostic criteria have been developed using biomarkers in cognitively normal (CN) adults. We implemented these criteria using an MRI biomarker previously associated with AD dementia, testing the hypothesis that individuals at high risk for preclinical AD would be at elevated risk for cognitive decline.$\backslash$n$\backslash$nMethods:$\backslash$nThe Alzheimer's Disease Neuroimaging Initiative database was interrogated for CN individuals. MRI data were processed using a published set of a priori regions of interest to derive a single measure known as the AD signature (ADsig). Each individual was classified as ADsig-low (≥1 SD below the mean: high risk for preclinical AD), ADsig-average (within 1 SD of mean), or ADsig-high (≥1 SD above mean). A 3-year cognitive decline outcome was defined a priori using change in Clinical Dementia Rating sum of boxes and selected neuropsychological measures.$\backslash$n$\backslash$nResults:$\backslash$nIndividuals at high risk for preclinical AD were more likely to experience cognitive decline, which developed in 21{\%} compared with 7{\%} of ADsig-average and 0{\%} of ADsig-high groups (p = 0.03). Logistic regression demonstrated that every 1 SD of cortical thinning was associated with a nearly tripled risk of cognitive decline (p = 0.02). Of those for whom baseline CSF data were available, 60{\%} of the high risk for preclinical AD group had CSF characteristics consistent with AD while 36{\%} of the ADsig-average and 19{\%} of the ADsig-high groups had such CSF characteristics (p = 0.1).$\backslash$n$\backslash$nConclusions:$\backslash$nThis approach to the detection of individuals at high risk for preclinical AD—identified in single CN individuals using this quantitative ADsig MRI biomarker—may provide investigators with a population enriched for AD pathobiology and with a relatively high likelihood of imminent cognitive decline consistent with prodromal AD.},
author = {Dickerson, Bradford C and Wolk, David A},
doi = {10.1212/WNL.0b013e31823efc6c},
file = {:C$\backslash$:/Dropbox/PhD/Articles/AnatStudy/Dickerson, Wolk - 2012 - MRI cortical thickness biomarker predicts AD-like CSF and cognitive decline in normal adults.pdf:pdf},
isbn = {1526-632X (Electronic)$\backslash$r0028-3878 (Linking)},
issn = {00283878},
journal = {Neurology},
number = {2},
pages = {84--90},
pmid = {22189451},
title = {{MRI cortical thickness biomarker predicts AD-like CSF and cognitive decline in normal adults}},
volume = {78},
year = {2012}
}
@article{Doll2012,
abstract = {The reward prediction error (RPE) theory of dopamine (DA) function has enjoyed great success in the neuroscience of learning and decision-making. This theory is derived from model-free reinforcement learning (RL), in which choices are made simply on the basis of previously realized rewards. Recently, attention has turned to correlates of more flexible, albeit computationally complex, model-based methods in the brain. These methods are distinguished from model-free learning by their evaluation of candidate actions using expected future outcomes according to a world model. Puzzlingly, signatures from these computations seem to be pervasive in the very same regions previously thought to support model-free learning. Here, we review recent behavioral and neural evidence about these two systems, in attempt to reconcile their enigmatic cohabitation in the brain. ?? 2012 Elsevier Ltd. All rights reserved.},
author = {Doll, Bradley B and Simon, Dylan A and Daw, Nathaniel D},
doi = {10.1016/j.conb.2012.08.003},
isbn = {0959-4388},
issn = {09594388},
journal = {Current Opinion in Neurobiology},
number = {6},
pages = {1075--1081},
pmid = {22959354},
title = {{The ubiquity of model-based reinforcement learning}},
url = {http://dx.doi.org/10.1016/j.conb.2012.08.003},
volume = {22},
year = {2012}
}
@article{Dutilh2012b,
abstract = {In many response time tasks, people slow down after they make an error. This phenomenon of post-error slowing (PES) is thought to reflect an increase in response caution, that is, a heightening of response thresholds in order to increase the probability of a correct response at the expense of response speed. In many empirical studies, PES is quantified as the difference in response time (RT) between post-error trials and post-correct trials. Here we demonstrate that this standard measurement method is prone to contamination by global fluctuations in performance over the course of an experiment. Diffusion model simulations show how global fluctuations in performance can cause either spurious detection of PES or masking of PES. Both confounds are highly undesirable and can be eliminated by a simple solution: quantify PES as the difference in RT between post-error trials and the associated pre-error trials. Experimental data are used as an empirical illustration. ?? 2012 Elsevier Inc..},
author = {Dutilh, Gilles and {Van Ravenzwaaij}, Don and Nieuwenhuis, Sander and {Van der Maas}, Han L J and Forstmann, Birte U and Wagenmakers, Eric-Jan},
doi = {10.1016/j.jmp.2012.04.001},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dutilh et al. - 2012 - How to measure post-error slowing A confound and a simple solution.pdf:pdf},
isbn = {00222496},
issn = {00222496},
journal = {Journal of Mathematical Psychology},
keywords = {Diffusion model,Error-monitoring,Post-error slowing,Sequential effects,Speeded Decision-making},
number = {3},
pages = {208--216},
title = {{How to measure post-error slowing: A confound and a simple solution}},
url = {http://dx.doi.org/10.1016/j.jmp.2012.04.001},
volume = {56},
year = {2012}
}
@article{Dutilh2012a,
abstract = {People tend to slow down after they make an error. This phenomenon, generally referred to as post-error slowing, has been hypothesized to reflect perceptual distraction, time wasted on irrelevant processes, an a priori bias against the response made in error, increased variability in a priori bias, or an increase in response caution. Although the response caution interpretation has dominated the empirical literature, little research has attempted to test this interpretation in the context of a formal process model. Here, we used the drift diffusion model to isolate and identify the psychological processes responsible for post-error slowing. In a very large lexical decision data set, we found that post-error slowing was associated with an increase in response caution and-to a lesser extent-a change in response bias. In the present data set, we found no evidence that post-error slowing is caused by perceptual distraction or time wasted on irrelevant processes. These results support a response-monitoring account of post-error slowing.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Dutilh, Gilles and Vandekerckhove, Joachim and Forstmann, Birte U and Keuleers, Emmanuel and Brysbaert, Marc and Wagenmakers, Eric-Jan},
doi = {10.3758/s13414-011-0243-2},
eprint = {arXiv:1011.1669v3},
isbn = {1943-393X (Electronic)$\backslash$n1943-3921 (Linking)},
issn = {1943-3921},
journal = {Attention, Perception, {\&} Psychophysics},
keywords = {Attention,Awareness,Decision Making,Discrimination (Psychology),Humans,Internal-External Control,Pattern Recognition,Problem Solving,Psychological Theory,Reaction Time,Risk-Taking,Semantics,Visual},
month = {feb},
number = {2},
pages = {454--465},
pmid = {22105857},
title = {{Testing theories of post-error slowing}},
url = {http://www.springerlink.com/index/10.3758/s13414-011-0243-2},
volume = {74},
year = {2012}
}
@article{Economides2014,
abstract = {Actions can lead to an immediate reward or punishment and a complex set of delayed outcomes. Adaptive choice necessitates the brain track and integrate both of these potential consequences. Here, we designed a sequential task whereby the decision to exploit or forego an available offer was contingent on comparing immediate value and a state-dependent future cost of expending a limited resource. Crucially, the dynamics of the task demanded frequent switches in policy based on an online computation of changing delayed consequences. We found that human subjects choose on the basis of a near-optimal integration of immediate reward and delayed consequences, with the latter computed in a prefrontal network. Within this network, anterior cingulate cortex (ACC) was dynamically coupled to ventromedial prefrontal cortex (vmPFC) when adaptive switches in choice were required. Our results suggest a choice architecture whereby interactions between ACC and vmPFC underpin an integration of immediate and delayed components of value to support flexible policy switching that accommodates the potential delayed consequences of an action.},
author = {Economides, Marcos and Guitart-Masip, Marc and Kurth-Nelson, Zeb and Dolan, Raymond J},
doi = {10.1523/JNEUROSCI.4313-13.2014},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Economides et al. - 2014 - Anterior Cingulate Cortex Instigates Adaptive Switches in Choice by Integrating Immediate and Delayed Compone.pdf:pdf},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {computational modeling,control,decision-making,fmri,prefrontal cortex,value},
number = {9},
pages = {3340--3349},
pmid = {24573291},
title = {{Anterior Cingulate Cortex Instigates Adaptive Switches in Choice by Integrating Immediate and Delayed Components of Value in Ventromedial Prefrontal Cortex}},
url = {http://www.jneurosci.org/content/34/9/3340.full?maxtoshow={\&}hits=10{\&}RESULTFORMAT={\&}andorexacttitle=and{\&}titleabstract=decision,+value,+risk,+uncertainty,+insula,+striatum,+pfc,+preference{\&}andorexacttitleabs=or{\&}andorexactfulltext=or{\&}searchid=1{\&}usestrictdates=},
volume = {34},
year = {2014}
}
@article{Fischl2000,
abstract = {Accurate and automated methods for measuring the thickness of human cerebral cortex could provide powerful tools for diagnosing and studying a variety of neurodegenerative and psychiatric disorders. Manual methods for estimating cortical thickness from neuroimaging data are labor intensive, requiring several days of effort by a trained anatomist. Furthermore, the highly folded nature of the cortex is problematic for manual techniques, frequently resulting in measurement errors in regions in which the cortical surface is not perpendicular to any of the cardinal axes. As a consequence, it has been impractical to obtain accurate thickness estimates for the entire cortex in individual subjects, or group statistics for patient or control populations. Here, we present an automated method for accurately measuring the thickness of the cerebral cortex across the entire brain and for generating crosssubject statistics in a coordinate system based on cortical anatomy. The intersubject standard deviation of the thickness measures is shown to be less than 0.5 mm, implying the ability to detect focal atrophy in small populations or even individual subjects. The reliability and accuracy of this new method are assessed by within-subject test–retest studies, as well as by comparison of cross-subject regional thickness measures with published values.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Fischl, Bruce and Dale, Anders M},
doi = {10.1073/pnas.200033797},
eprint = {NIHMS150003},
file = {:C$\backslash$:/Dropbox/PhD/Articles/AnatStudy/Fischl, Dale - 2000 - Measuring the thickness of the human cerebral cortex from magnetic resonance images.pdf:pdf},
isbn = {0027-8424 (Print)$\backslash$n0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Cerebral Cortex,Cerebral Cortex: cytology,Cerebral Cortex: radiography,Computer-Assisted,Humans,Image Processing,Magnetic Resonance Imaging},
number = {20},
pages = {11050--11055},
pmid = {10984517},
title = {{Measuring the thickness of the human cerebral cortex from magnetic resonance images}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.200033797},
volume = {97},
year = {2000}
}
@article{Fitts1966,
abstract = {Examines the capacity of Os to adapt to changes in the relative emphasis on speed vs. accuracy of responses. 3 matched groups of 6 Os each were trained for 3 days in a choice reaction-time (RT) task, with feedback indicating both speed and accuracy. Emphasis on speed decreased mean RT but increased errors. A control group, working without an exact payoff or immediate feedback, showed somewhat greater within- and between-S variability than did either the speed or accuracy groups and was at an intermediate level on all performance measures. Similar distributions of RTs were found for correct responses and for errors as was predicted by a sequential sampling and decision model of choice RT. RT distributions for all Os were approximately normal under a set for speed, but under accuracy instructions some Os gave highly skewed distributions.},
author = {Fitts, Paul M.},
doi = {10.1037/h0023232},
isbn = {0022-1015},
issn = {0022-1015},
journal = {Journal of experimental psychology},
number = {6},
pages = {849--857},
pmid = {5939364},
title = {{Cognitive aspects of information processing. 3. Set for speed versus accuracy.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0023232},
volume = {71},
year = {1966}
}
@article{FitzGerald2012,
abstract = {Estimating the value of potential actions is crucial for learning and adaptive behavior. We know little about how the human brain represents action-specific value outside of motor areas. This is, in part, due to a difficulty in detecting the neural correlates of value using conventional (region of interest) functional magnetic resonance imaging (fMRI) analyses, due to a potential distributed representation of value. We address this limitation by applying a recently developed multivariate decoding method to high-resolution fMRI data in subjects performing an instrumental learning task. We found evidence for action-specific value signals in circumscribed regions, specifically ventromedial prefrontal cortex, putamen, thalamus, and insula cortex. In contrast, action-independent value signals were more widely represented across a large set of brain areas. Using multivariate Bayesian model comparison, we formally tested whether value-specific responses are spatially distributed or coherent. We found strong evidence that both action-specific and action-independent value signals are represented in a distributed fashion. Our results suggest that a surprisingly large number of classical reward-related areas contain distributed representations of action-specific values, representations that are likely to mediate between reward and adaptive behavior.},
author = {FitzGerald, Thomas H B and Friston, Karl J and Dolan, Raymond J},
doi = {10.1523/JNEUROSCI.3254-12.2012},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/FitzGerald, Friston, Dolan - 2012 - Action-Specific Value Signals in Reward-Related Regions of the Human Brain.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {46},
pages = {16417--16423},
pmid = {23152624},
title = {{Action-Specific Value Signals in Reward-Related Regions of the Human Brain}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3254-12.2012},
volume = {32},
year = {2012}
}
@article{Fjell2012b,
abstract = {When people make mistakes in speeded cognitive tasks, their response time on the next trial will typically be slower. This is referred to as post-error slowing (PES), and is important for optimization of performance, but its exact function remains to be decided. However, although PES is relatively stable over time, we have almost no knowledge about how PES is affected by structural brain characteristics. The aim of this study was to test to what extent white matter (WM) macro- and microstructure can account for individual differences in PES. PES was calculated for 255 healthy participants who performed a modified version of the Eriksen flanker task and underwent structural magnetic resonance imaging and diffusion tensor imaging (DTI). PES was positively related to WM volume in the caudal and rostral middle and superior frontal, medial orbitofrontal gyri and pars orbitalis. DTI analyses with tract-based spatial statistics (TBSS) showed that mean diffusivity in the superior longitudinal fasciculus, inferior fronto-occipital fasciculus and anterior thalamic radiation, as well as axial diffusivity in the corpus callosum, was negatively related to PES. Path analysis demonstrated that WM micro- and macrostructure were complementary in accounting for PES. It is concluded that individual differences in WM characteristics can partly explain why some people are better at adjusting their behavior in response to poor performance than others. ?? 2012 Elsevier Inc.},
author = {Fjell, Anders M and Westlye, Lars T and Amlien, Inge K and Walhovd, Kristine B},
doi = {10.1016/j.neuroimage.2012.03.007},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fjell et al. - 2012 - A multi-modal investigation of behavioral adjustment Post-error slowing is associated with white matter characteri.pdf:pdf},
isbn = {1095-9572 (Electronic)$\backslash$n1053-8119 (Linking)},
issn = {10538119},
journal = {NeuroImage},
keywords = {Aging,Cognitive control,Diffusion tensor imaging,Magnetic resonance imaging,Morphometry,Post-error slowing},
number = {1},
pages = {195--205},
pmid = {22433658},
title = {{A multi-modal investigation of behavioral adjustment: Post-error slowing is associated with white matter characteristics}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2012.03.007},
volume = {61},
year = {2012}
}
@article{Forstmann2016,
abstract = {Sequential sampling models assume that people make speeded decisions by gradually accumulating noisy information until a threshold of evidence is reached. In cognitive science, one such model-the diffusion decision model-is now regularly used to decompose task performance into underlying processes such as the quality of information processing, response caution, and a priori bias. In the cognitive neurosciences, the diffusion decision model has recently been adopted as a quantitative tool to study the neural basis of decision making under time pressure. We present a selective overview of several recent applications and extensions of the diffusion decision model in the cognitive neurosciences.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Forstmann, Birte U and Ratcliff, Roger and Wagenmakers, Eric-Jan},
doi = {10.1146/annurev-psych-122414-033645},
eprint = {15334406},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Forstmann, Ratcliff, Wagenmakers - 2016 - Sequential Sampling Models in Cognitive Neuroscience Advantages, Applications, and Extensions.pdf:pdf},
isbn = {1545-2085 (Electronic)$\backslash$r0066-4308 (Linking)},
issn = {0066-4308},
journal = {Annual Review of Psychology},
keywords = {decision making,diffusion decision model,drift rate,information accumulation,response time,speed-accuracy trade-off},
number = {1},
pages = {641--666},
pmid = {26393872},
title = {{Sequential Sampling Models in Cognitive Neuroscience: Advantages, Applications, and Extensions}},
url = {http://www.annualreviews.org/doi/10.1146/annurev-psych-122414-033645},
volume = {67},
year = {2016}
}
@article{Foster1870,
author = {Foster, M},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Cognitive Control/Foster - 1870 - The Velocity of Thought.pdf:pdf},
journal = {Nature},
pages = {2--4},
title = {{The Velocity of Thought}},
volume = {2},
year = {1870}
}
@article{Frank2011,
abstract = {Background: The neurobiology of bulimia nervosa (BN) is poorly understood. Recent animal literature suggests that binge eating is associated with altered brain dopamine (DA) reward function. In this study, we wanted to investigate DA-related brain reward learning in BN. Methods: Ill BN (n = 20, age: mean = 25.2, SD = 5.3 years) and healthy control women (CW) (n = 23, age: mean = 27.2, SD = 6.4 years) underwent functional magnetic resonance brain imaging together with application of a DA-related reward learning paradigm, the temporal difference (TD) model. That task involves association learning between conditioned visual and unconditioned taste stimuli, as well as unexpected violation of those learned associations. Study participants also completed the Sensitivity to Reward and Punishment Questionnaire. Results: Bulimia nervosa individuals showed reduced brain response compared with CW for unexpected receipt and omission of taste stimuli, as well as reduced brain regression response to the TD computer model generated reward values, in insula, ventral putamen, amygdala, and orbitofrontal cortex. Those results were qualitatively similar in BN individuals who were nondepressed and unmedicated. Binge/purge frequency in BN inversely predicted reduced TD model response. Bulimia nervosa individuals showed significantly higher Sensitivity to Reward and Punishment compared with CW. Conclusions: This is the first study that relates reduced brain DA responses in BN to the altered learning of associations between arbitrary visual stimuli and taste rewards. This attenuated response is related to frequency of binge/purge episodes in BN. The brain DA neurotransmitter system could be an important treatment target for BN. ?? 2011 Society of Biological Psychiatry.},
author = {Frank, Guido K W and Reynolds, Jeremy R and Shott, Megan E and O'Reilly, Randall C},
doi = {10.1016/j.biopsych.2011.05.011},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Frank et al. - 2011 - Altered temporal difference learning in bulimia nervosa.pdf:pdf},
isbn = {1873-2402 (Electronic)$\backslash$r0006-3223 (Linking)},
issn = {00063223},
journal = {Biological Psychiatry},
keywords = {Bulimia nervosa,computational,dopamine,imaging,reward,temporal difference model},
number = {8},
pages = {728--735},
pmid = {21718969},
title = {{Altered temporal difference learning in bulimia nervosa}},
url = {http://dx.doi.org/10.1016/j.biopsych.2011.05.011},
volume = {70},
year = {2011}
}
@article{Frank2015,
author = {Frank, Michael J and Gagne, Chris and Nyhus, Erika and Masters, Sean and Wiecki, Thomas V and Cavanagh, James F and Badre, David},
doi = {10.1523/JNEUROSCI.2036-14.2015},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Frank et al. - 2015 - fMRI and EEG Predictors of Dynamic Decision Parameters during Human Reinforcement Learning.pdf:pdf},
journal = {The Journal of neuroscience},
keywords = {basal ganglia,decision making,drift diffusion model,prefrontal cortex,subthalamic nucleus},
number = {2},
pages = {485--494},
title = {{fMRI and EEG Predictors of Dynamic Decision Parameters during Human Reinforcement Learning}},
volume = {35},
year = {2015}
}
@article{Frank2007a,
abstract = {What are the genetic and neural components that support adaptive learning from positive and negative outcomes? Here, we show with genetic analyses that three independent dopaminergic mechanisms contribute to reward and avoidance learning in humans. A polymorphism in the DARPP-32 gene, associated with striatal dopamine function, predicted relatively better probabilistic reward learning. Conversely, the C957T polymorphism of the DRD2 gene, associated with striatal D2 receptor function, predicted the degree to which participants learned to avoid choices that had been probabilistically associated with negative outcomes. The Val/Met polymorphism of the COMT gene, associated with prefrontal cortical dopamine function, predicted participants' ability to rapidly adapt behavior on a trial-to-trial basis. These findings support a neurocomputational dissociation between striatal and prefrontal dopaminergic mechanisms in reinforcement learning. Computational maximum likelihood analyses reveal independent gene effects on three reinforcement learning parameters that can explain the observed dissociations.},
author = {Frank, Michael J and Moustafa, Ahmed A and Haughey, Heather and Curran, Tim and Hutchison, Kent},
doi = {10.1073/pnas.0706111104},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Frank et al. - 2007 - Genetic triple dissociation reveals multiple roles for dopamine in reinforcement learning(2).pdf:pdf},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Adolescent,Adult,Algorithms,Behavioral,Brain,Brain: physiology,Catechol O-Methyltransferase,Catechol O-Methyltransferase: genetics,Dopamine,Dopamine D2,Dopamine D2: genetics,Dopamine and cAMP-Regulated Phosphoprotein 32,Dopamine and cAMP-Regulated Phosphoprotein 32: gen,Dopamine: genetics,Dopamine: physiology,Female,Genetic,Genetics,Humans,Male,Models,Polymorphism,Psychological,Receptors,Reinforcement (Psychology)},
month = {oct},
number = {41},
pages = {16311--6},
pmid = {17913879},
title = {{Genetic triple dissociation reveals multiple roles for dopamine in reinforcement learning.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2042203{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {104},
year = {2007}
}
@article{Frank2004,
abstract = {To what extent do we learn from the positive versus negative outcomes of our decisions? The neuromodulator dopamine plays a key role in these reinforcement learning processes. Patients with Parkinson's disease, who have depleted dopamine in the basal ganglia, are impaired in tasks that require learning from trial and error. Here, we show, using two cognitive procedural learning tasks, that Parkinson's patients off medication are better at learning to avoid choices that lead to negative outcomes than they are at learning from positive outcomes. Dopamine medication reverses this bias, making patients more sensitive to positive than negative outcomes. This pattern was predicted by our biologically based computational model of basal ganglia-dopamine interactions in cognition, which has separate pathways for "Go" and "NoGo" responses that are differentially modulated by positive and negative reinforcement.},
author = {Frank, Michael J and Seeberger, Lauren C and O'Reilly, Randall C},
doi = {10.1126/science.1102941},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Frank, Seeberger, O'Reilly - 2004 - By carrot or by stick cognitive reinforcement learning in parkinsonism(2).pdf:pdf},
issn = {1095-9203},
journal = {Science},
keywords = {Aged,Antiparkinson Agents,Antiparkinson Agents: therapeutic use,Basal Ganglia,Basal Ganglia: physiopathology,Cognition,Computer Simulation,Dopamine,Dopamine: physiology,Feedback,Female,Frontal Lobe,Frontal Lobe: physiopathology,Humans,Learning,Male,Matched-Pair Analysis,Middle Aged,Models,Neurological,Parkinson Disease,Parkinson Disease: drug therapy,Parkinson Disease: physiopathology,Parkinson Disease: psychology,Probability,Psychological,Reinforcement (Psychology)},
month = {dec},
number = {5703},
pages = {1940--1943},
pmid = {15528409},
title = {{By carrot or by stick: cognitive reinforcement learning in parkinsonism.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15528409},
volume = {306},
year = {2004}
}
@article{Freeman2014,
abstract = {Motivating stimuli provoke action tendencies that sometimes lead to unwanted behavior (e.g., eating chocolate when trying to diet) [1-4]. Implementing control over these provocations is essential to healthy functioning [1, 5]; however, few laboratory-based models of such control exist. Here we developed a novel task in which thirsty human subjects made instrumental responses to obtain a juice reward (Go trials) or were required to withhold responding (NoGo trials) in the presence of a rewarded (CS+) or unrewarded (CS-) conditioned stimulus. For Go trials, single-pulse transcranial magnetic stimulation revealed a rapid increase in motor activity for CS+ versus CS-, preceding more vigorous instrumental responding. Critically, successful NoGo trials resulted in suppression of motor activity for CS+, but not CS-. Moreover, while there was broad excitation in the hand muscles in Go trials, suppression in NoGo trials was selective to the effector that could obtain reward. These results show that response suppression can be triggered by a motivational stimulus, thus providing a richer model of self-control than classic cognitive psychology paradigms. {\textcopyright} 2014 Elsevier Ltd.},
author = {Freeman, Scott M and Razhas, Ieva and Aron, Adam R},
doi = {10.1016/j.cub.2013.12.019},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Freeman, Razhas, Aron - 2014 - Top-down response suppression mitigates action tendencies triggered by a motivating stimulus.pdf:pdf},
issn = {09609822},
journal = {Current Biology},
number = {2},
pages = {212--216},
pmid = {24412209},
title = {{Top-down response suppression mitigates action tendencies triggered by a motivating stimulus}},
url = {http://dx.doi.org/10.1016/j.cub.2013.12.019},
volume = {24},
year = {2014}
}
@article{Friston2009,
abstract = {This paper considers prediction and perceptual categorization as an inference problem that is solved by the brain. We assume that the brain models the world as a hierarchy or cascade of dynamical systems that encode causal structure in the sensorium. Perception is equated with the optimization or inversion of these internal models, to explain sensory data. Given a model of how sensory data are generated, we can invoke a generic approach to model inversion, based on a free energy bound on the model's evidence. The ensuing free-energy formulation furnishes equations that prescribe the process of recognition, i.e. the dynamics of neuronal activity that represent the causes of sensory input. Here, we focus on a very general model, whose hierarchical and dynamical structure enables simulated brains to recognize and predict trajectories or sequences of sensory states. We first review hierarchical dynamical models and their inversion. We then show that the brain has the necessary infrastructure to implement this inversion and illustrate this point using synthetic birds that can recognize and categorize birdsongs.},
author = {Friston, Karl J and Kiebel, Stefan},
doi = {10.1098/rstb.2008.0300},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Friston, Kiebel - 2009 - Predictive coding under the free-energy principle(2).pdf:pdf;:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Friston, Kiebel - 2009 - Predictive coding under the free-energy principle(3).pdf:pdf},
issn = {1471-2970},
journal = {Philosophical transactions of the Royal Society of London. Series B, Biological sciences},
keywords = {Animal,Animals,Birds,Birds: physiology,Brain,Brain: physiology,Computer Simulation,Concept Formation,Concept Formation: physiology,Humans,Models,Neurological,Perception,Perception: physiology,Recognition (Psychology),Recognition (Psychology): physiology,Vocalization},
month = {may},
number = {1521},
pages = {1211--21},
pmid = {19528002},
title = {{Predictive coding under the free-energy principle.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2666703{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {364},
year = {2009}
}
@article{Garrison2013,
abstract = {Activation likelihood estimation (ALE) meta-analyses were used to examine the neural correlates of prediction error in reinforcement learning. The findings are interpreted in the light of current computational models of learning and action selection. In this context, particular consideration is given to the comparison of activation patterns from studies using instrumental and Pavlovian conditioning, and where reinforcement involved rewarding or punishing feedback. The striatum was the key brain area encoding for prediction error, with activity encompassing dorsal and ventral regions for instrumental and Pavlovian reinforcement alike, a finding which challenges the functional separation of the striatum into a dorsal 'actor' and a ventral 'critic'. Prediction error activity was further observed in diverse areas of predominantly anterior cerebral cortex including medial prefrontal cortex and anterior cingulate cortex. Distinct patterns of prediction error activity were found for studies using rewarding and aversive reinforcers; reward prediction errors were observed primarily in the striatum while aversive prediction errors were found more widely including insula and habenula. ?? 2013 Elsevier Ltd.},
author = {Garrison, Jane and Erdeniz, Burak and Done, John},
doi = {10.1016/j.neubiorev.2013.03.023},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Garrison, Erdeniz, Done - 2013 - Prediction error in reinforcement learning A meta-analysis of neuroimaging studies.pdf:pdf},
isbn = {1873-7528 (Electronic)$\backslash$r0149-7634 (Linking)},
issn = {01497634},
journal = {Neuroscience and Biobehavioral Reviews},
keywords = {Actor-critic,Habenula,Prediction error,Punishment,Reinforcement learning,Reward,Striatum},
number = {7},
pages = {1297--1310},
pmid = {23567522},
title = {{Prediction error in reinforcement learning: A meta-analysis of neuroimaging studies}},
url = {http://dx.doi.org/10.1016/j.neubiorev.2013.03.023},
volume = {37},
year = {2013}
}
@article{Glascher2012,
abstract = {A considerable body of previous research on the prefrontal cortex (PFC) has helped characterize the regional specificity of various cognitive functions, such as cognitive control and decision making. Here we provide definitive findings on this topic, using a neuropsychological approach that takes advantage of a unique dataset accrued over several decades. We applied voxel-based lesion-symptom mapping in 344 individuals with focal lesions (165 involving the PFC) who had been tested on a comprehensive battery of neuropsychological tasks. Two distinct functional-anatomical networks were revealed within the PFC: one associated with cognitive control (response inhibition, conflict monitoring, and switching), which included the dorsolateral prefrontal cortex and anterior cingulate cortex and a second associated with value-based decision-making, which included the orbitofrontal, ventromedial, and frontopolar cortex. Furthermore, cognitive control tasks shared a common performance factor related to set shifting that was linked to the rostral anterior cingulate cortex. By contrast, regions in the ventral PFC were required for decision-making. These findings provide detailed causal evidence for a remarkable functional-anatomical specificity in the human PFC.},
author = {Gl{\"{a}}scher, Jan and Adolphs, Ralph and Damasio, Hanna and Bechara, Antoine and Rudrauf, David and Calamia, Matthew and Paul, Lynn K and Tranel, Daniel},
doi = {10.1073/pnas.1206608109},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gl{\"{a}}scher et al. - 2012 - Lesion mapping of cognitive control and value-based decision making in the prefrontal cortex.pdf:pdf},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {Cognition,Cognition: physiology,Decision Making,Decision Making: physiology,Executive Function,Executive Function: physiology,Gyrus Cinguli,Gyrus Cinguli: physiology,Humans,Iowa,Linear Models,Magnetic Resonance Imaging,Nerve Net,Nerve Net: physiology,Neuropsychological Tests,Prefrontal Cortex,Prefrontal Cortex: pathology,Prefrontal Cortex: physiology,Social Values,Tomography,X-Ray Computed},
month = {sep},
number = {36},
pages = {14681--6},
pmid = {22908286},
title = {{Lesion mapping of cognitive control and value-based decision making in the prefrontal cortex.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3437894{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {109},
year = {2012}
}
@article{Glascher2010,
abstract = {Reinforcement learning (RL) uses sequential experience with situations (" states" ) and outcomes to assess actions. Whereas model-free RL uses this experience directly, in the form of a reward prediction error (RPE), model-based RL uses it indirectly, building a model of the state transition and outcome structure of the environment, and evaluating actions by searching this model. A state prediction error (SPE) plays a central role, reporting discrepancies between the current model and the observed state transitions. Using functional magnetic resonance imaging in humans solving a probabilistic Markov decision task, we found the neural signature of an SPE in the intraparietal sulcus and lateral prefrontal cortex, in addition to the previously well-characterized RPE in the ventral striatum. This finding supports the existence of two unique forms of learning signal in humans, which may form the basis of distinct computational strategies for guiding behavior. {\textcopyright} 2010 Elsevier Inc.},
author = {Gl{\"{a}}scher, Jan and Daw, Nathaniel D and Dayan, Peter and O'Doherty, John P},
doi = {10.1016/j.neuron.2010.04.016},
isbn = {0896-6273},
issn = {08966273},
journal = {Neuron},
number = {4},
pages = {585--595},
pmid = {20510862},
title = {{States versus rewards: Dissociable neural prediction error signals underlying model-based and model-free reinforcement learning}},
url = {http://dx.doi.org/10.1016/j.neuron.2010.04.016},
volume = {66},
year = {2010}
}
@article{Guitart-Masip2012a,
abstract = {Decision-making invokes two fundamental axes of control: affect or valence, spanning reward and punishment, and effect or action, spanning invigoration and inhibition. We studied the acquisition of instrumental responding in healthy human volunteers in a task in which we orthogonalized action requirements and outcome valence. Subjects were much more successful in learning active choices in rewarded conditions, and passive choices in punished conditions. Using computational reinforcement-learning models, we teased apart contributions from putatively instrumental and Pavlovian components in the generation of the observed asymmetry during learning. Moreover, using model-based fMRI, we showed that BOLD signals in striatum and substantia nigra/ventral tegmental area (SN/VTA) correlated with instrumentally learnt action values, but with opposite signs for go and no-go choices. Finally, we showed that successful instrumental learning depends on engagement of bilateral inferior frontal gyrus. Our behavioral and computational data showed that instrumental learning is contingent on overcoming inherent and plastic Pavlovian biases, while our neuronal data showed this learning is linked to unique patterns of brain activity in regions implicated in action and inhibition respectively. ?? 2012 Elsevier Inc.},
author = {Guitart-Masip, Marc and Huys, Quentin J M and Fuentemilla, Lluis and Dayan, Peter and Duzel, Emrah and Dolan, Raymond J.},
doi = {10.1016/j.neuroimage.2012.04.024},
isbn = {1095-9572 (Electronic)$\backslash$n1053-8119 (Linking)},
issn = {10538119},
journal = {NeuroImage},
keywords = {Action,Instrumental,Learning,Pavlovian,Striatum},
number = {1},
pages = {154--166},
pmid = {22548809},
title = {{Go and no-go learning in reward and punishment: Interactions between affect and effect}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2012.04.024},
volume = {62},
year = {2012}
}
@article{Hajcak2003,
author = {Hajcak, Greg and McDonald, Nicole and Simons, Robert F},
doi = {10.1111/1469-8986.00107},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hajcak, McDonald, Simons - 2003 - To err is autonomic Error-related brain potentials, ANS activity, and post-error compensatory behav(2).pdf:pdf},
issn = {00485772},
journal = {Psychophysiology},
month = {nov},
number = {6},
pages = {895--903},
title = {{To err is autonomic: Error-related brain potentials, ANS activity, and post-error compensatory behavior}},
url = {http://doi.wiley.com/10.1111/1469-8986.00107},
volume = {40},
year = {2003}
}
@article{Heitz2014,
abstract = {There are few behavioral effects as ubiquitous as the speed-accuracy tradeoff (SAT). From insects to rodents to primates, the tendency for decision speed to covary with decision accuracy seems an inescapable property of choice behavior. Recently, the SAT has received renewed interest, as neuroscience approaches begin to uncover its neural underpinnings and computational models are compelled to incorporate it as a necessary benchmark. The present work provides a comprehensive overview of SAT. First, I trace its history as a tractable behavioral phenomenon and the role it has played in shaping mathematical descriptions of the decision process. Second, I present a "users guide" of SAT methodology, including a critical review of common experimental manipulations and analysis techniques and a treatment of the typical behavioral patterns that emerge when SAT is manipulated directly. Finally, I review applications of this methodology in several domains.},
author = {Heitz, Richard P.},
doi = {10.3389/fnins.2014.00150},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Post error slowing/Heitz - 2014 - The speed-accuracy tradeoff History, physiology, methodology, and behavior.pdf:pdf},
isbn = {1662-4548},
issn = {1662453X},
journal = {Frontiers in Neuroscience},
keywords = {Decision-making,Speed-accuracy tradeoff},
pmid = {24966810},
title = {{The speed-accuracy tradeoff: History, physiology, methodology, and behavior}},
volume = {8},
year = {2014}
}
@article{Herz2016a,
abstract = {If humans are faced with difficult choices when making decisions, the ability to slow down responses becomes critical in order to avoid suboptimal choices. Current models of decision making assume that the subthalamic nucleus (STN) mediates this function by elevating decision thresholds, thereby requiring more evidence to be accumulated before responding [1-9]. However, direct electrophysiological evidence for the exact role of STN during adjustment of decision thresholds is lacking. Here, we show that trial-by-trial variations in STN low-frequency oscillatory activity predict adjustments of decision thresholds before subjects make a response. The relationship between STN activity and decision thresholds critically depends on the subjects' level of cautiousness. While increased oscillatory activity of the STN predicts elevated decision thresholds during high levels of cautiousness, it predicts decreased decision thresholds during low levels of cautiousness. This context-dependent relationship may be mediated by increased influence of the medial prefrontal cortex (mPFC)-STN pathway on decision thresholds during high cautiousness. Subjects who exhibit a stronger increase in phase alignment of low-frequency oscillatory activity in mPFC and STN before making a response have higher decision thresholds and commit fewer erroneous responses. Together, our results demonstrate that STN low-frequency oscillatory activity and corresponding mPFC-STN coupling are involved in determining how much evidence subjects accumulate before making a decision. This finding might explain why deep-brain stimulation of the STN can impair subjects' ability to slow down responses and can induce impulsive suboptimal decisions.},
author = {Herz, Damian M and Zavala, Baltazar A and Bogacz, Rafal and Brown, Peter},
doi = {10.1016/j.cub.2016.01.051},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Herz et al. - 2016 - Neural Correlates of Decision Thresholds in the Human Subthalamic Nucleus.pdf:pdf},
issn = {09609822},
journal = {Current Biology},
number = {7},
pages = {916--920},
pmid = {26996501},
title = {{Neural Correlates of Decision Thresholds in the Human Subthalamic Nucleus}},
url = {http://dx.doi.org/10.1016/j.cub.2016.01.051},
volume = {26},
year = {2016}
}
@article{Hester2007,
abstract = {The magnitude of posterior medial frontal cortex (pMFC) activity during commission of an error has been shown to relate to adaptive posterror changes in response behavior on the trial immediately following. In the present article, we examined neural activity during and after error commission to identify its relationship to sustained posterror behavior changes that led to performance improvements several trials into the future. The standard task required participants to inhibit a prepotent motor response during infrequent lure trials, which were randomly interspersed among numerous go trials. Posterror behavior was manipulated by introducing a dynamic condition, in which an error on a lure trial ensured that the next lure would appear within two to seven go trials. Behavioral data indicated significantly higher levels of posterror slowing and accuracy during the dynamic condition, as well as fewer consecutive lure errors. Bilateral prefrontal cortex (PFC) and pMFC activity during the posterror period, but not during commission of the error itself, was associated with increased posterror slowing. Activity within two of these regions (right PFC and pMFC) also predicted success on the next lure trial. The findings support a relationship between pMFC/PFC activity and adaptive posterror behavior change, and the discrepancy between these findings and those of previous studies-in the present study, this relationship was detected during the posterror period rather than during commission of the error itself--may have resulted from the requirements of the present task. Implications of this discrepancy for the flexibility of cognitive control are discussed.},
author = {Hester, Robert and Barre, Natalie and Mattingley, Jason B and Foxe, John J and Garavan, Hugh},
doi = {10.3758/CABN.7.4.317},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hester et al. - 2007 - Avoiding another mistake error and posterror neural activity associated with adaptive posterror behavior change.pdf:pdf},
issn = {1530-7026},
journal = {Cognitive, affective {\&} behavioral neuroscience},
keywords = {Adaptation,Adult,Computer-Assisted,Data Interpretation,Female,Humans,Image Processing,Magnetic Resonance Imaging,Male,Prefrontal Cortex,Prefrontal Cortex: physiology,Psychological,Psychological: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Self Concept,Statistical},
month = {dec},
number = {4},
pages = {317--26},
pmid = {18189005},
title = {{Avoiding another mistake: error and posterror neural activity associated with adaptive posterror behavior change.}},
volume = {7},
year = {2007}
}
@article{Hester2009,
abstract = {Failure to adapt performance following an error is a debilitating symptom of many neurological and psychiatric conditions. Healthy individuals readily adapt their behavior in response to an error, an ability thought to be subserved by the posterior medial frontal cortex (pMFC). However, it remains unclear how humans adaptively alter cognitive control behavior when they reencounter situations that were previously failed minutes or days ago. Using functional magnetic resonance imaging, we examined neural activity during a Go/No-go response inhibition task that provided the opportunity for participants to learn from their errors. When they failed to inhibit their response, they were shown the same target stimulus during the next No-go trial, which itself could occur up to 20 trials after its initial presentation. Activity within the pMFC was significantly greater for initial errors that were subsequently corrected than for errors that were repeated later in the display sequence. Moreover, pMFC activity during errors predicted future responses despite a sizeable interval (on average 12 trials) between an error and the next No-go stimulus. Our results indicate that changes in cognitive control performance can be predicted using error-related activity. The increased likelihood of adaptive changes occurring during periods of recent success is consistent with models of error-related activity that argue for the influence of outcome expectancy (Holroyd and Coles, 2002; Brown and Braver, 2005). The findings may also help to explain the diminished error-related neural activity in such clinical conditions as schizophrenia, as well as the propensity for perseverative behavior in these clinical groups.},
author = {Hester, Robert and Madeley, Janelle and Murphy, Kevin and Mattingley, Jason B},
doi = {10.1523/JNEUROSCI.4337-08.2009},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hester et al. - 2009 - Learning from errors error-related neural activity predicts improvements in future inhibitory control performance.pdf:pdf},
isbn = {0270-6474},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {22},
pages = {7158--7165},
pmid = {19494138},
title = {{Learning from errors: error-related neural activity predicts improvements in future inhibitory control performance.}},
volume = {29},
year = {2009}
}
@article{Hutchison2013,
abstract = {The brain must dynamically integrate, coordinate, and respond to internal and external stimuli across multiple time scales. Non-invasive measurements of brain activity with fMRI have greatly advanced our understanding of the large-scale functional organization supporting these fundamental features of brain function. Conclusions from previous resting-state fMRI investigations were based upon static descriptions of functional connectivity (FC), and only recently studies have begun to capitalize on the wealth of information contained within the temporal features of spontaneous BOLD FC. Emerging evidence suggests that dynamic FC metrics may index changes in macroscopic neural activity patterns underlying critical aspects of cognition and behavior, though limitations with regard to analysis and interpretation remain. Here, we review recent findings, methodological considerations, neural and behavioral correlates, and future directions in the emerging field of dynamic FC investigations. {\textcopyright} 2013 Elsevier Inc.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Hutchison, R Matthew and Womelsdorf, Thilo and Allen, Elena A and Bandettini, Peter A and Calhoun, Vince D and Corbetta, Maurizio and {Della Penna}, Stefania and Duyn, Jeff H and Glover, Gary H and Gonzalez-Castillo, Javier and Handwerker, Daniel A and Keilholz, Shella and Kiviniemi, Vesa and Leopold, David A and de Pasquale, Francesco and Sporns, Olaf and Walter, Martin and Chang, Catie},
doi = {10.1016/j.neuroimage.2013.05.079},
eprint = {NIHMS150003},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Dynamic Functional Connectivity/Hutchison et al. - 2013 - Dynamic functional connectivity Promise, issues, and interpretations.pdf:pdf},
isbn = {1095-9572 (Electronic)$\backslash$r1053-8119 (Linking)},
issn = {10538119},
journal = {NeuroImage},
keywords = {Dynamics,Fluctuations,Functional MRI (fMRI),Functional connectivity,Resting state,Spontaneous activity},
pages = {360--378},
pmid = {23707587},
title = {{Dynamic functional connectivity: Promise, issues, and interpretations}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2013.05.079},
volume = {80},
year = {2013}
}
@article{Huys2016,
author = {Huys, Quentin J M and Maia, Tiago V and Frank, Michael J},
doi = {10.1038/nn.4238},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Huys, Maia, Frank - 2016 - Computational psychiatry as a bridge between neuroscience and clinical applications.pdf:pdf},
issn = {1097-6256},
journal = {Nature Neuroscience},
keywords = {computational neuroscience,computational psychiatry,machine learning,modeling,reinforcement learning,response prediction,translational,treatment-},
number = {3},
pages = {404--413},
title = {{Computational psychiatry as a bridge between neuroscience and clinical applications}},
volume = {19},
year = {2016}
}
@article{Jentzsch2009,
abstract = {People often become slower in their performance after committing an error, which is usually explained by strategic control adjustments towards a more conservative response threshold. The present study tested an alternative hypothesis for explaining posterror slowing in terms of behavioural interferences resulting from error monitoring by manipulating stimulus contrast and categorization difficulty in a choice reaction time task. The response-stimulus interval (RSI) was either short or long, using a between-subject (Experiment 1) and a within-subject design (Experiment 2). Posterror slowing was larger and posterror accuracy lower in short than in long RSI situations. Effects of stimulus contrast disappeared in posterror trials when RSI was short. At long RSIs, stimulus contrast was additive with posterror slowing. The results support the idea that at least two mechanisms contribute to posterror slowing: a capacity-limited error-monitoring process with the strongest influence at short RSIs and a criterion adjustment mechanism at longer RSIs.},
author = {Jentzsch, Ines and Dudschig, Carolin},
doi = {10.1080/17470210802240655},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jentzsch, Dudschig - 2009 - Why do we slow down after an error Mechanisms underlying the effects of posterror slowing(2).pdf:pdf},
issn = {1747-0226},
journal = {Quarterly journal of experimental psychology (2006)},
keywords = {Adaptation, Psychological,Adaptation, Psychological: physiology,Adult,Analysis of Variance,Decision Making,Decision Making: physiology,Feedback, Psychological,Feedback, Psychological: physiology,Female,Humans,Internal-External Control,Male,Neuropsychological Tests,Photic Stimulation,Reaction Time,Time Factors,Young Adult},
month = {mar},
number = {2},
pages = {209--18},
pmid = {18720281},
title = {{Why do we slow down after an error? Mechanisms underlying the effects of posterror slowing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18720281},
volume = {62},
year = {2009}
}
@article{Jocham2011,
abstract = {A large body of evidence exists on the role of dopamine in reinforcement learning. Less is known about how dopamine shapes the relative impact of Jocham, G., Klein, T. a, {\&} Ullsperger, M. (2011). Dopamine-mediated reinforcement learning signals in the striatum and ventromedial prefrontal cortex underlie value-based choices. The Journal of Neuroscience : The Official Journal of the Society for Neuroscience, 31(5), 1606–13. doi:10.1523/JNEUROSCI.3904-10.2011positive and negative outcomes to guide value-based choices. We combined administration of the dopamine D(2) receptor antagonist amisulpride with functional magnetic resonance imaging in healthy human volunteers. Amisulpride did not affect initial reinforcement learning. However, in a later transfer phase that involved novel choice situations requiring decisions between two symbols based on their previously learned values, amisulpride improved participants' ability to select the better of two highly rewarding options, while it had no effect on choices between two very poor options. During the learning phase, activity in the striatum encoded a reward prediction error. In the transfer phase, in the absence of any outcome, ventromedial prefrontal cortex (vmPFC) continually tracked the learned value of the available options on each trial. Both striatal prediction error coding and tracking of learned value in the vmPFC were predictive of subjects' choice performance in the transfer phase, and both were enhanced under amisulpride. These findings show that dopamine-dependent mechanisms enhance reinforcement learning signals in the striatum and sharpen representations of associative values in prefrontal cortex that are used to guide reinforcement-based decisions.},
author = {Jocham, Gerhard and Klein, Tilmann A and Ullsperger, Markus},
doi = {10.1523/JNEUROSCI.3904-10.2011},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jocham, Klein, Ullsperger - 2011 - Dopamine-mediated reinforcement learning signals in the striatum and ventromedial prefrontal cortex u.pdf:pdf},
issn = {1529-2401},
journal = {Journal of Neuroscience},
keywords = {Adult,Choice Behavior,Choice Behavior: drug effects,Corpus Striatum,Corpus Striatum: drug effects,Corpus Striatum: physiology,Dopamine,Dopamine Antagonists,Dopamine Antagonists: pharmacology,Dopamine D2,Dopamine D2: antagonists {\&} inhibitors,Dopamine: physiology,Female,Humans,Magnetic Resonance Imaging,Male,Models,Neurological,Neuropsychological Tests,Prefrontal Cortex,Prefrontal Cortex: drug effects,Prefrontal Cortex: physiology,Psychomotor Performance,Psychomotor Performance: drug effects,Receptors,Reinforcement (Psychology),Reinforcement Schedule,Reward,Signal Transduction,Signal Transduction: drug effects,Signal Transduction: physiology,Sulpiride,Sulpiride: analogs {\&} derivatives,Sulpiride: pharmacology,Time Factors},
month = {feb},
number = {5},
pages = {1606--13},
pmid = {21289169},
title = {{Dopamine-mediated reinforcement learning signals in the striatum and ventromedial prefrontal cortex underlie value-based choices.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21289169},
volume = {31},
year = {2011}
}
@article{Kahnt2009,
abstract = {It has been suggested that the target areas of dopaminergic midbrain neurons, the dorsal (DS) and ventral striatum (VS), are differently involved in reinforcement learning especially as actor and critic. Whereas the critic learns to predict rewards, the actor maintains action values to guide future decisions. The different midbrain connections to the DS and the VS seem to play a critical role in this functional distinction. Here, subjects performed a dynamic, reward-based decision-making task during fMRI acquisition. A computational model of reinforcement learning was used to estimate the different effects of positive and negative reinforcements on future decisions for each subject individually. We found that activity in both the DS and the VS correlated with reward prediction errors. Using functional connectivity, we show that the DS and the VS are differentially connected to different midbrain regions (possibly corresponding to the substantia nigra [SN] and the ventral tegmental area [VTA], respectively). However, only functional connectivity between the DS and the putative SN predicted the impact of different reinforcement types on future behavior. These results suggest that connections between the putative SN and the DS are critical for modulating action values in the DS according to both positive and negative reinforcements to guide future decision making.},
author = {Kahnt, Thorsten and Park, Soyoung Q and Cohen, Michael X and Beck, Anne and Heinz, Andreas and Wrase, Jana},
doi = {10.1162/jocn.2009.21092},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kahnt et al. - 2009 - Dorsal striatal-midbrain connectivity in humans predicts how reinforcements are used to guide decisions(2).pdf:pdf},
issn = {0898-929X},
journal = {Journal of cognitive neuroscience},
keywords = {Adult,Brain Mapping,Conditioning, Operant,Corpus Striatum,Corpus Striatum: blood supply,Corpus Striatum: physiology,Decision Making,Decision Making: physiology,Female,Humans,Image Processing, Computer-Assisted,Image Processing, Computer-Assisted: methods,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Male,Mesencephalon,Mesencephalon: blood supply,Mesencephalon: physiology,Neural Pathways,Neural Pathways: blood supply,Neural Pathways: physiology,Neuropsychological Tests,Oxygen,Oxygen: blood,Pattern Recognition, Visual,Pattern Recognition, Visual: physiology,Photic Stimulation,Photic Stimulation: methods,Predictive Value of Tests,Reaction Time,Reaction Time: physiology,Reinforcement (Psychology),Young Adult},
month = {jul},
number = {7},
pages = {1332--45},
pmid = {18752410},
title = {{Dorsal striatal-midbrain connectivity in humans predicts how reinforcements are used to guide decisions.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18752410},
volume = {21},
year = {2009}
}
@incollection{Kamin1969,
author = {Kamin, Leon J},
booktitle = {Punishment and aversive behavior},
editor = {Campbell, B. A. and Church, M. R},
pages = {279--296},
publisher = {Appleton-Century-Crofts},
title = {{Predictability, surprise, attention, and conditioning.}},
year = {1969}
}
@article{Kerns2004,
abstract = {Conflict monitoring by the anterior cingulate cortex (ACC) has been posited to signal a need for greater cognitive control, producing neural and behavioral adjustments. However, the very occurrence of behavioral adjustments after conflict has been questioned, along with suggestions that there is no direct evidence of ACC conflict-related activity predicting subsequent neural or behavioral adjustments in control. Using the Stroop color-naming task and controlling for repetition effects, we demonstrate that ACC conflict-related activity predicts both greater prefrontal cortex activity and adjustments in behavior, supporting a role of ACC conflict monitoring in the engagement of cognitive control.},
author = {Kerns, John G and Cohen, Jonathan D and MacDonald, Angus W and Cho, Raymond Y and Stenger, V Andrew and Carter, Cameron S},
doi = {10.1126/science.1089910},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kerns et al. - 2004 - Anterior cingulate conflict monitoring and adjustments in control.pdf:pdf},
issn = {1095-9203},
journal = {Science},
keywords = {Adult,Brain Mapping,Cognition,Conflict (Psychology),Cues,Female,Frontal Lobe,Frontal Lobe: physiology,Gyrus Cinguli,Gyrus Cinguli: physiology,Humans,Magnetic Resonance Imaging,Male,Neuropsychological Tests,Prefrontal Cortex,Prefrontal Cortex: physiology,Reaction Time},
month = {feb},
number = {5660},
pages = {1023--6},
pmid = {14963333},
title = {{Anterior cingulate conflict monitoring and adjustments in control.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/14963333},
volume = {303},
year = {2004}
}
@article{King2010,
abstract = {Error monitoring by the posterior medial frontal cortex (pMFC) has been linked to post-error behavioral adaptation effects and cognitive control dynamics in lateral prefrontal cortex (LPFC). It remains unknown, however, whether control adjustments following errors produce post-error behavioral adjustments (PEBAs) by inhibiting inappropriate responses or facilitating goal-directed ones. Here we used functional magnetic resonance imaging to investigate the hemodynamic correlates of PEBAs in a stimulus-response compatibility task. Our task was designed to test whether PEBAs are implemented by suppressing motor responses primed by irrelevant stimulus features (face location), redirecting attention to relevant features (face gender), or both or neither of these possibilities. Independent of PEBAs, error-related pMFC activation was followed by post-error recruitment of prefrontal and parietal control regions and, crucially, both (1) suppressed response-related activity in sensorimotor cortex and (2) enhanced target processing in face-sensitive sensory cortex ("fusiform face area"). More importantly, by investigating the covariation between post-error hemodynamic activity and individual differences in PEBAs, we showed that modulation of task-related motor and sensory processing was dependent on whether participants produced generally slower responses ("post-error slowing"; PES) or selectively reduced interference effects ("post-error reduction of interference"; PERI), respectively. Each of these behaviorally dependent effects was mediated by distinct LPFC control mechanisms (PES: inferior frontal junction; PERI: superior frontal sulcus). While establishing relationships between PEBAs and cognitive control, our findings suggest that the neural architecture underlying sequential behavioral adaptation may be determined primarily by how control is executed by the individual when adjustments are needed.},
annote = {Use classical mean error RT minus mean correct RT for PES},
author = {King, Joseph A and Korb, Franziska M and von Cramon, D Yves and Ullsperger, Markus},
doi = {10.1523/JNEUROSCI.3274-10.2010},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/King et al. - 2010 - Post-error behavioral adjustments are facilitated by activation and suppression of task-relevant and task-irrelevan.pdf:pdf},
issn = {1529-2401},
journal = {Journal of Neuroscience},
keywords = {Adult,Attention,Attention: physiology,Brain Mapping,Cerebral Cortex,Cerebral Cortex: physiology,Computer-Assisted,Humans,Image Processing,Magnetic Resonance Imaging,Male,Nerve Net,Nerve Net: physiology,Neurons,Neurons: physiology,Photic Stimulation,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology},
month = {sep},
number = {38},
pages = {12759--69},
pmid = {20861380},
title = {{Post-error behavioral adjustments are facilitated by activation and suppression of task-relevant and task-irrelevant information processing.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/20861380},
volume = {30},
year = {2010}
}
@article{Klein2007,
abstract = {The role of dopamine in monitoring negative action outcomes and feedback-based learning was tested in a neuroimaging study in humans grouped according to the dopamine D2 receptor gene polymorphism DRD2-TAQ-IA. In a probabilistic learning task, A1-allele carriers with reduced dopamine D2 receptor densities learned to avoid actions with negative consequences less efficiently. Their posterior medial frontal cortex (pMFC), involved in feedback monitoring, responded less to negative feedback than others' did. Dynamically changing interactions between pMFC and hippocampus found to underlie feedback-based learning were reduced in A1-allele carriers. This demonstrates that learning from errors requires dopaminergic signaling. Dopamine D2 receptor reduction seems to decrease sensitivity to negative action consequences, which may explain an increased risk of developing addictive behaviors in A1-allele carriers.},
author = {Klein, Tilmann A and Neumann, Jane and Reuter, Martin and Hennig, J{\"{u}}rgen and {Von Cramon}, D.Y. and Ullsperger, Markus},
doi = {10.1126/science.1145044},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Klein et al. - 2007 - Genetically determined differences in learning from errors.pdf:pdf},
isbn = {1095-9203 (Electronic)},
issn = {1095-9203},
journal = {Science},
keywords = {Adult,Alleles,Avoidance Learning,Basal Ganglia,Basal Ganglia: physiology,Brain Mapping,Dopamine,Dopamine D2,Dopamine D2: genetics,Dopamine D2: metabolism,Dopamine: physiology,Feedback,Frontal Lobe,Frontal Lobe: physiology,Genetic,Hippocampus,Hippocampus: physiology,Humans,Learning,Magnetic Resonance Imaging,Male,Nucleus Accumbens,Nucleus Accumbens: physiology,Polymorphism,Psychological,Receptors,Reinforcement (Psychology),Signal Transduction},
number = {5856},
pages = {1642--1645},
pmid = {18063800},
title = {{Genetically determined differences in learning from errors}},
volume = {318},
year = {2007}
}
@article{Kumar2008,
abstract = {Anhedonia is a core symptom of major depressive disorder (MDD), long thought to be associated with reduced dopaminergic function. However, most antidepressants do not act directly on the dopamine system and all antidepressants have a delayed full therapeutic effect. Recently, it has been proposed that antidepressants fail to alter dopamine function in antidepressant unresponsive MDD. There is compelling evidence that dopamine neurons code a specific phasic (short duration) reward-learning signal, described by temporal difference (TD) theory. There is no current evidence for other neurons coding a TD reward-learning signal, although such evidence may be found in time. The neuronal substrates of the TD signal were not explored in this study. Phasic signals are believed to have quite different properties to tonic (long duration) signals. No studies have investigated phasic reward-learning signals in MDD. Therefore, adults with MDD receiving long-term antidepressant medication, and comparison controls both unmedicated and acutely medicated with the antidepressant citalopram, were scanned using fMRI during a reward-learning task. Three hypotheses were tested: first, patients with MDD have blunted TD reward-learning signals; second, controls given an antidepressant acutely have blunted TD reward-learning signals; third, the extent of alteration in TD signals in major depression correlates with illness severity ratings. The results supported the hypotheses. Patients with MDD had significantly reduced reward-learning signals in many non-brainstem regions: ventral striatum (VS), rostral and dorsal anterior cingulate, retrosplenial cortex (RC), midbrain and hippocampus. However, the TD signal was increased in the brainstem of patients. As predicted, acute antidepressant administration to controls was associated with a blunted TD signal, and the brainstem TD signal was not increased by acute citalopram administration. In a number of regions, the magnitude of the abnormal signals in MDD correlated with illness severity ratings. The findings highlight the importance of phasic reward-learning signals, and are consistent with the hypothesis that antidepressants fail to normalize reward-learning function in antidepressant-unresponsive MDD. Whilst there is evidence that some antidepressants acutely suppress dopamine function, the long-term action of virtually all antidepressants is enhanced dopamine agonist responsiveness. This distinction might help to elucidate the delayed action of antidepressants. Finally, analogous to recent work in schizophrenia, the finding of abnormal phasic reward-learning signals in MDD implies that an integrated understanding of symptoms and treatment mechanisms is possible, spanning physiology, phenomenology and pharmacology.},
author = {Kumar, Poornima and Waiter, Gordon and Ahearn, Trevor and Milders, Marteen and Reid, Ian and Steele, J Douglas},
doi = {10.1093/brain/awn136},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kumar et al. - 2008 - Abnormal temporal difference reward-learning signals in major depression.pdf:pdf},
isbn = {1460-2156 (Electronic)$\backslash$r0006-8950 (Linking)},
issn = {00068950},
journal = {Brain},
keywords = {Citalopram,Major depressive disorder,Reward-learning,Temporal difference signals},
number = {8},
pages = {2084--2093},
pmid = {18579575},
title = {{Abnormal temporal difference reward-learning signals in major depression}},
volume = {131},
year = {2008}
}
@article{Laming1979,
abstract = {Some data are presented showing the changes in choice-reaction time (CRT) and the probability of error (PE) on the five trials following an error in a two-choice experiment. The magnitudes of the increase in RT and the decrease in PE are different according as the error-trial stimulus is re-presented or the alternative stimulus is preservec. In addition, RT is quicker to recover its equilibrium value than is PE. This pattern of changes implicates two distinct adjustments to the underlying decision process following an error: (i) a selective outward adjustment of the boundary at which the error was uttered, and (ii) a delay, with respect to presentation of the reaction stimulus, of the epoch at which the subject begins sampling information from the stimulus display. When these ideas are concatenated with the sequential probability-ratio-test model for CRT, a theoretical relation can be derived between the difference in mean RT for an error and for the same response given correctly, on the one hand, and the decrease in PE on the trial following an error, given that the alternate stimulus is presented, on the other. This relation is satisfied by the data. ?? 1979.},
author = {Laming, Donald},
doi = {10.1016/0001-6918(79)90026-X},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Laming - 1979 - Choice reaction performance following an error.pdf:pdf},
isbn = {0001-6918},
issn = {00016918},
journal = {Acta Psychologica},
number = {3},
pages = {199--224},
title = {{Choice reaction performance following an error}},
volume = {43},
year = {1979}
}
@article{Lee2014,
abstract = {There is accumulating neural evidence to support the existence of two distinct systems for guiding action selection, a deliberative "model-based" and a reflexive "model-free" system. However, little is known about how the brain determines which of these systems controls behavior at one moment in time. We provide evidence for an arbitration mechanism that allocates the degree of control over behavior by model-based and model-free systems as a function of the reliability of their respective predictions. We show that the inferior lateral prefrontal and frontopolar cortex encode both reliability signals and the output of a comparison between those signals, implicating these regions in the arbitration process. Moreover, connectivity between these regions and model-free valuation areas is negatively modulated by the degree of model-based control in the arbitrator, suggesting that arbitration may work through modulation of the model-free valuation system when the arbitrator deems that the model-based system should drive behavior.},
author = {Lee, Sang Wan and Shimojo, Shinsuke and O'Doherty, John P},
doi = {10.1016/j.neuron.2013.11.028},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Shimojo, O'Doherty - 2014 - Neural Computations Underlying Arbitration between Model-Based and Model-free Learning(2).pdf:pdf;:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lee, Shimojo, O'Doherty - 2014 - Neural computations underlying arbitration between model-based and model-free learning(3).pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Adult,Brain,Brain Mapping,Brain: blood supply,Brain: physiology,Computer Simulation,Computer-Assisted,Decision Making,Female,Goals,Humans,Image Processing,Learning,Learning: physiology,Magnetic Resonance Imaging,Male,Models,Neurological,Oxygen,Oxygen: blood,Psychophysics,Young Adult},
month = {feb},
number = {3},
pages = {687--99},
pmid = {24507199},
title = {{Neural computations underlying arbitration between model-based and model-free learning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24507199},
volume = {81},
year = {2014}
}
@article{Lenartowicz2010,
abstract = {The goal of cognitive neuroscience is to map mental functions onto their neural substrates. We argue here that this goal requires a formal approach to the characterization of mental processes, and we present one such approach by using ontologies to describe cognitive processes and their relations. Using a classifier analysis of data from the BrainMap database, we examine the concept of 'cognitive control' to determine whether the proposed component processes in this domain are mapped to independent neural systems. These results show that some subcomponents can be uniquely classified, whereas others cannot, suggesting that these different components may vary in their ontological reality. We relate these concepts to the broader emerging field of phenomics, which aims to characterize cognitive phenotypes on a global scale.},
author = {Lenartowicz, Agatha and Kalar, Donald J and Congdon, Eliza and Poldrack, Russell A},
doi = {10.1111/j.1756-8765.2010.01100.x},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lenartowicz et al. - 2010 - Towards an Ontology of Cognitive Control.pdf:pdf},
isbn = {1756-8757},
issn = {17568757},
journal = {Topics in Cognitive Science},
keywords = {Classification,Cognitive control,Executive function,FMRI,Meta-analysis,Neuroimaging,Ontology,Phenomics,Working memory},
number = {4},
pages = {678--692},
pmid = {25164049},
title = {{Towards an Ontology of Cognitive Control}},
volume = {2},
year = {2010}
}
@article{Logothetis2001,
abstract = {Functional magnetic resonance imaging (fMRI) is widely used to study the operational organization of the human brain, but the exact relationship between the measured fMRI signal and the underlying neural activity is unclear. Here we present simultaneous intracortical recordings of neural signals and fMRI responses. We compared local field potentials (LFPs), single- and multi-unit spiking activity with highly spatio-temporally resolved blood-oxygen-level-dependent (BOLD) fMRI responses from the visual cortex of monkeys. The largest magnitude changes were observed in LFPs, which at recording sites characterized by transient responses were the only signal that significantly correlated with the haemodynamic response. Linear systems analysis on a trial-by-trial basis showed that the impulse response of the neurovascular system is both animal- and site-specific, and that LFPs yield a better estimate of BOLD responses than the multi-unit responses. These findings suggest that the BOLD contrast mechanism reflects the input and intracortical processing of a given area rather than its spiking output.},
author = {Logothetis, Nikos K and Pauls, Jon and Augath, Mark and Trinath, Torsten and Oeltermann, Axel},
doi = {10.1038/35084005},
isbn = {0028-0836 (Print)$\backslash$r0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {6843},
pages = {150--157},
pmid = {11449264},
title = {{Neurophysiological investigation of the basis of the fMRI signal}},
url = {http://www.nature.com/doifinder/10.1038/35084005},
volume = {412},
year = {2001}
}
@article{Madsen2010,
abstract = {Cognitive control of thoughts, actions and emotions is important for normal behaviour and the development of such control continues throughout childhood and adolescence. Several lines of evidence suggest that response inhibition is primarily mediated by a right-lateralized network involving inferior frontal gyrus (IFG), presupplementary motor cortex (preSMA), and subthalamic nucleus. Though the brain's fibre tracts are known to develop during childhood, little is known about how fibre tract development within this network relates to developing behavioural control. Here we examined the relationship between response inhibition, as measured with the stop-signal task, and indices of regional white matter microstructure in typically-developing children. We hypothesized that better response inhibition performance would be associated with higher fractional anisotropy (FA) in fibre tracts within right IFG and preSMA after controlling for age. Mean FA and diffusivity values were extracted from right and left IFG and preSMA. As hypothesized, faster response inhibition was significantly associated with higher FA and lower perpendicular diffusivity in both the right IFG and the right preSMA, possibly reflecting faster speed of neural conduction within more densely packed or better myelinated fibre tracts. Moreover, both of these effects remained significant after controlling for age and whole brain estimates of these DTI parameters. Interestingly, right IFG and preSMA FA contributed additively to the prediction of performance variability. Observed associations may be related to variation in phase of maturation, to activity-dependent alterations in the network subserving response inhibition, or to stable individual differences in underlying neural system connectivity. {\textcopyright} 2009 Elsevier Ltd.},
author = {Madsen, Kathrine Skak and Baar{\'{e}}, William F C and Vestergaard, Martin and Skimminge, Arnold and Ejersbo, Lisser Rye and Rams{\o}y, Thomas Z and Gerlach, Christian and {\AA}keson, Per and Paulson, Olaf B and Jernigan, Terry L},
doi = {10.1016/j.neuropsychologia.2009.11.001},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd/Mendeley Desktop/Downloaded/Madsen et al. - 2010 - Response inhibition is associated with white matter microstructure in children.pdf:pdf},
isbn = {1873-3514 (Electronic)$\backslash$n0028-3932 (Linking)},
issn = {00283932},
journal = {Neuropsychologia},
keywords = {Brain maturation,Cognitive development,Diffusion tensor imaging,Executive control,Fractional anisotropy,MRI},
number = {4},
pages = {854--862},
pmid = {19909763},
title = {{Response inhibition is associated with white matter microstructure in children}},
volume = {48},
year = {2010}
}
@article{Maia2011,
abstract = {Over the last decade and a half, reinforcement learning models have fostered an increasingly sophisticated understanding of the functions of dopamine and cortico-basal ganglia-thalamo-cortical (CBGTC) circuits. More recently, these models, and the insights that they afford, have started to be used to understand important aspects of several psychiatric and neurological disorders that involve disturbances of the dopaminergic system and CBGTC circuits. We review this approach and its existing and potential applications to Parkinson's disease, Tourette's syndrome, attention-deficit/hyperactivity disorder, addiction, schizophrenia and preclinical animal models used to screen new antipsychotic drugs. The approach's proven explanatory and predictive power bodes well for the continued growth of computational psychiatry and computational neurology.},
author = {Maia, Tiago V and Frank, Michael J},
doi = {10.1038/nn.2723},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Reinforcement Learning/Maia, Frank - 2011 - From reinforcement learning models to psychiatric and neurological disorders.pdf:pdf},
isbn = {1546-1726 (Electronic)$\backslash$n1097-6256 (Linking)},
issn = {1097-6256},
journal = {Nature Neuroscience},
number = {2},
pages = {154--162},
pmid = {21270784},
title = {{From reinforcement learning models to psychiatric and neurological disorders}},
url = {http://www.nature.com/doifinder/10.1038/nn.2723},
volume = {14},
year = {2011}
}
@article{Makris2007,
abstract = {Attention-deficit/hyperactivity disorder (ADHD) has been associated with structural alterations in brain networks influencing cognitive and motor behaviors. Volumetric studies in children identify abnormalities in cortical, striatal, callosal, and cerebellar regions. In a prior volumetric study, we found that ADHD adults had significantly smaller overall cortical gray matter, prefrontal, and anterior cingulate volumes than matched controls. Thickness and surface area are additional indicators of integrity of cytoarchitecture in the cortex. To expand upon our earlier results and further refine the regions of structural abnormality, we carried out a structural magnetic resonance imaging study of cortical thickness in the same sample of adults with ADHD (n = 24) and controls (n = 18), hypothesizing that the cortical networks underlying attention and executive function (EF) would be most affected. Compared with healthy adults, adults with ADHD showed selective thinning of cerebral cortex in the networks that subserve attention and EF. In the present study, we found significant cortical thinning in ADHD in a distinct cortical network supporting attention especially in the right hemisphere involving the inferior parietal lobule, the dorsolateral prefrontal, and the anterior cingulate cortices. This is the first documentation that ADHD in adults is associated with thinner cortex in the cortical networks that modulate attention and EF.},
author = {Makris, Nikos and Biederman, Joseph and Valera, Eve M and Bush, George and Kaiser, Jonathan and Kennedy, David N and Caviness, Verne S and Faraone, Stephen V and Seidman, Larry J},
doi = {10.1093/cercor/bhl047},
file = {:C$\backslash$:/Dropbox/PhD/Articles/AnatStudy/Makris et al. - 2007 - Cortical thinning of the attention and executive function networks in adults with attention-deficithyperactivity.pdf:pdf},
isbn = {1047-3211 (Print)$\backslash$r1047-3211 (Linking)},
issn = {10473211},
journal = {Cerebral Cortex},
keywords = {ADHD,Attention,Cerebral cortex,Cortical thickness,Executive function},
number = {6},
pages = {1364--1375},
pmid = {16920883},
title = {{Cortical thinning of the attention and executive function networks in adults with attention-deficit/hyperactivity disorder}},
volume = {17},
year = {2007}
}
@article{Mathias2017,
abstract = {Processing speed is impaired in patients with psychosis, and deteriorates as a function of normal aging. These observations, in combination with other lines of research, suggest that psychosis may be a syndrome of accelerated aging. But do patients with psychosis perform poorly on tasks of processing speed for the same reasons as older adults? Fifty-one patients with psychotic illnesses and 90 controls with similar mean IQ (aged 19-69 years, all African American) completed a computerized processing-speed task, reminiscent of the classic digit-symbol coding task. The data were analyzed using the drift-diffusion model (DDM), and Bayesian inference was used to determine whether psychosis and aging had similar or divergent effects on the DDM parameters. Psychosis and aging were both associated with poor performance, but had divergent effects on the DDM parameters. Patients had lower information-processing efficiency ("drift rate") and longer nondecision time than controls, and psychosis per se did not influence response caution. By contrast, the primary effect of aging was to increase response caution, and had inconsistent effects on drift rate and nondecision time across patients and controls. The results reveal that psychosis and aging influenced performance in different ways, suggesting that the processing-speed impairment in psychosis is more than just accelerated aging. This study also demonstrates the potential utility of computational models and Bayesian inference for finely mapping the contributions of cognitive functions on simple neurocognitive tests.},
author = {Mathias, Samuel R and Knowles, Emma E M and Barrett, Jennifer and Leach, Olivia and Buccheri, Sebastiano and Beetham, Tamara and Blangero, John and Poldrack, Russell A and Glahn, David C},
doi = {10.1093/schbul/sbw168},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Drift Diffusion/Mathias et al. - 2017 - The Processing-Speed Impairment in Psychosis Is More Than Just Accelerated Aging.pdf:pdf},
issn = {17451701},
journal = {Schizophrenia Bulletin},
keywords = {Bayesian inference,aging,computational psychiatry,digit-symbol,processing speed,psychosis},
number = {4},
pages = {814--823},
pmid = {28062652},
title = {{The Processing-Speed Impairment in Psychosis Is More Than Just Accelerated Aging}},
volume = {43},
year = {2017}
}
@article{Miller2000,
abstract = {One of the enduring mysteries of brain function concerns the process of cognitive control. How does complex and seemingly willful behaviour emerge from interactions between millions of neurons? This has long been suspected to depend on the prefrontal cortex--the neocortex at the anterior end of the brain--but now we are beginning to uncover its neural basis. Nearly all intended behaviour is learned and so depends on a cognitive system that can acquire and implement the 'rules of the game' needed to achieve a given goal in a given situation. Studies indicate that the prefrontal cortex is central in this process. It provides an infrastructure for synthesizing a diverse range of information that lays the foundation for the complex forms of behaviour observed in primates.},
author = {Miller, Earl K},
doi = {10.1038/35036228},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Miller - 2000 - The prefrontal cortex and cognitive control.pdf:pdf},
isbn = {1471-0048},
issn = {1471-003X},
journal = {Nature Reviews Neuroscience},
number = {1},
pages = {59--65},
pmid = {11252769},
title = {{The prefrontal cortex and cognitive control.}},
url = {http://www.nature.com/doifinder/10.1038/35036228{\%}5Cnpapers3://publication/doi/10.1038/35036228},
volume = {1},
year = {2000}
}
@article{Mnih2015,
abstract = {The theory of reinforcement learning provides a normative account 1 , deeply rooted in psychological 2 and neuroscientific 3 perspectives on animal behaviour, of how agents may optimize their control of an environment. To use reinforcement learning successfully in situations approaching real-world complexity, however, agents are confronted with a difficult task: they must derive efficient representations of the environment from high-dimensional sensory inputs, and use these to generalize past experience to new situations. Remarkably, humans and other animals seem to solve this problem through a harmonious combination of reinforcement learning and hierarchical sensory pro-cessing systems 4,5 , the former evidenced by a wealth of neural data revealing notable parallels between the phasic signals emitted by dopa-minergic neurons and temporal difference reinforcement learning algorithms 3 . While reinforcement learning agents have achieved some successes in a variety of domains 6–8 , their applicability has previously been limited to domains in which useful features can be handcrafted, or to domains with fully observed, low-dimensional state spaces. Here we use recent advances in training deep neural networks 9–11 to develop a novel artificial agent, termed a deep Q-network, that can learn successful policies directly from high-dimensional sensory inputs using end-to-end reinforcement learning. We tested this agent on the challenging domain of classic Atari 2600 games 12},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
doi = {10.1038/nature14236},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mnih et al. - 2015 - Human-level control through deep reinforcement learning.pdf:pdf},
issn = {0028-0836},
journal = {Nature},
number = {7540},
pages = {529--533},
title = {{Human-level control through deep reinforcement learning}},
url = {http://dx.doi.org/10.1038/nature14236},
volume = {518},
year = {2015}
}
@article{Montague1996,
abstract = {We develop a theoretical framework that shows how mesencephalic dopamine systems could distribute to their targets a signal that represents information about future expectations. In particular, we show how activity in the cerebral cortex can make predictions about future receipt of reward and how fluctuations in the activity levels of neurons in diffuse dopamine systems above and below baseline levels would represent errors in these predictions that are delivered to cortical and subcortical targets. We present a model for how such errors could be constructed in a real brain that is consistent with physiological results for a subset of dopaminergic neurons located in the ventral tegmental area and surrounding dopaminergic neurons. The theory also makes testable predictions about human choice behavior on a simple decision-making task. Furthermore, we show that, through a simple influence on synaptic plasticity, fluctuations in dopamine release can act to change the predictions in an appropriate manner.},
author = {Montague, P Read and Dayan, Peter and Sejnowski, Terrence J},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Montague, Dayan, Sejnowski - 1996 - A framework for mesencephalic dopamine systems based on predictive Hebbian learning.pdf:pdf},
isbn = {0270-6474},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {and more cells respond,diffuse ascending systems,dopamine,prediction,reinforcement learning,reward,synaptic plasticity,the stimulus,to the onset of},
number = {5},
pages = {1936--1947},
pmid = {8774460},
title = {{A framework for mesencephalic dopamine systems based on predictive Hebbian learning.}},
volume = {16},
year = {1996}
}
@article{Montague2012b,
abstract = {Computational ideas pervade many areas of science and have an integrative explanatory role in neuroscience and cognitive science. However, computational depictions of cognitive function have had surprisingly little impact on the way we assess mental illness because diseases of the mind have not been systematically conceptualized in computational terms. Here, we outline goals and nascent efforts in the new field of computational psychiatry, which seeks to characterize mental dysfunction in terms of aberrant computations over multiple scales. We highlight early efforts in this area that employ reinforcement learning and game theoretic frameworks to elucidate decision-making in health and disease. Looking forwards, we emphasize a need for theory development and large-scale computational phenotyping in human subjects.},
author = {Montague, P Read and Dolan, Raymond J and Friston, Karl J and Dayan, Peter},
doi = {10.1016/j.tics.2011.11.018},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Montague et al. - 2012 - Computational psychiatry(2).pdf:pdf;:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Montague et al. - 2012 - Computational psychiatry(3).pdf:pdf},
issn = {1879-307X},
journal = {Trends in cognitive sciences},
keywords = {Biological Psychiatry,Biological Psychiatry: methods,Brain,Brain: physiopathology,Computational Biology,Computational Biology: methods,Concept Formation,Decision Making,Game Theory,Humans,Mental Disorders,Mental Disorders: physiopathology,Models,Neurological,Neurosciences,Neurosciences: methods,Reinforcement (Psychology)},
month = {jan},
number = {1},
pages = {72--80},
pmid = {22177032},
title = {{Computational psychiatry}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22177032 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3556822{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {16},
year = {2012}
}
@article{Moustafa2015,
abstract = {In this study, we tested reward- and punishment learning performance using a probabilistic classification learning task in patients with schizophrenia (. n=. 37) and healthy controls (. n=. 48). We also fit subjects' data using a Drift Diffusion Model (DDM) of simple decisions to investigate which components of the decision process differ between patients and controls. Modeling results show between-group differences in multiple components of the decision process. Specifically, patients had slower motor/encoding time, higher response caution (favoring accuracy over speed), and a deficit in classification learning for punishment, but not reward, trials. The results suggest that patients with schizophrenia adopt a compensatory strategy of favoring accuracy over speed to improve performance, yet still show signs of a deficit in learning based on negative feedback. Our data highlights the importance of applying fitting models (particularly drift diffusion models) to behavioral data. The implications of these findings are discussed relative to theories of schizophrenia and cognitive processing.},
author = {Moustafa, Ahmed A. and K{\'{e}}ri, Szabolcs and Somlai, Zsuzsanna and Balsdon, Tarryn and Frydecka, Dorota and Misiak, Blazej and White, Corey},
doi = {10.1016/j.bbr.2015.05.024},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Drift Diffusion/Moustafa et al. - 2015 - Drift diffusion model of reward and punishment learning in schizophrenia Modeling and experimental data.pdf:pdf},
issn = {18727549},
journal = {Behavioural Brain Research},
keywords = {Decision making,Drift diffusion model (DDM),Punishment,Reinforcement learning,Reward,Schizophrenia},
pages = {147--154},
pmid = {26005124},
title = {{Drift diffusion model of reward and punishment learning in schizophrenia: Modeling and experimental data}},
url = {http://dx.doi.org/10.1016/j.bbr.2015.05.024},
volume = {291},
year = {2015}
}
@article{Niv2009,
abstract = {A wealth of research focuses on the decision-making processes that animals and humans employ when selecting actions in the face of reward and punishment. Initially such work stemmed from psychological investigations of conditioned behavior, and explanations of ... $\backslash$n},
author = {Niv, Yael},
doi = {10.1016/j.jmp.2008.12.005},
file = {:C$\backslash$:/Dropbox/PhD/Articles/RLvsCC/Niv2009.pdf:pdf},
isbn = {0022-2496},
issn = {00222496},
journal = {Journal of Mathematical Psychology},
number = {3},
pages = {139--154},
pmid = {1000104255},
title = {{Reinforcement learning in the brain}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0022249608001181{\%}5Cnpapers3://publication/uuid/AF94836A-43B3-4489-99A9-D911D0069CAB},
volume = {53},
year = {2009}
}
@article{Niv2012,
abstract = {Humans and animals are exquisitely, though idiosyncratically, sensitive to risk or variance in the outcomes of their actions. Economic, psychological, and neural aspects of this are well studied when information about risk is provided explicitly. However, we must normally learn about outcomes from experience, through trial and error. Traditional models of such reinforcement learning focus on learning about the mean reward value of cues and ignore higher order moments such as variance. We used fMRI to test whether the neural correlates of human reinforcement learning are sensitive to experienced risk. Our analysis focused on anatomically delineated regions of a priori interest in the nucleus accumbens, where blood oxygenation level-dependent (BOLD) signals have been suggested as correlating with quantities derived from reinforcement learning. We first provide unbiased evidence that the raw BOLD signal in these regions corresponds closely to a reward prediction error. We then derive from this signal the learned values of cues that predict rewards of equal mean but different variance and show that these values are indeed modulated by experienced risk. Moreover, a close neurometric-psychometric coupling exists between the fluctuations of the experience-based evaluations of risky options that we measured neurally and the fluctuations in behavioral risk aversion. This suggests that risk sensitivity is integral to human learning, illuminating economic models of choice, neuroscientific models of affective learning, and the workings of the underlying neural mechanisms.},
author = {Niv, Yael and Edlund, Jeffrey A and Dayan, Peter and O'Doherty, John P},
doi = {10.1523/JNEUROSCI.5498-10.2012},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Niv et al. - 2012 - Neural prediction errors reveal a risk-sensitive reinforcement-learning process in the human brain.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$n0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {Adolescent,Brain,Choice Behavior,Classical,Conditioning,Female,Humans,Learning,Male,Models,Nucleus Accumbens,Predictive Value of Tests,Psychological,Reinforcement (Psychology),Reward,Risk-Taking,Young Adult},
number = {2},
pages = {551--562},
pmid = {22238090},
title = {{Neural prediction errors reveal a risk-sensitive reinforcement-learning process in the human brain.}},
url = {http://discovery.ucl.ac.uk/1336509/},
volume = {32},
year = {2012}
}
@article{Niv2008,
abstract = {The recognition that computational ideas from reinforcement learning are relevant to the study of neural circuits has taken the cognitive neuroscience community by storm. A central tenet of these models is that discrepancies between actual and expected outcomes can be used for learning. Neural correlates of such prediction-error signals have been observed now in midbrain dopaminergic neurons, striatum, amygdala and even prefrontal cortex, and models incorporating prediction errors have been invoked to explain complex phenomena such as the transition from goal-directed to habitual behavior. Yet, like any revolution, the fast-paced progress has left an uneven understanding in its wake. Here, we provide answers to ten simple questions about prediction errors, with the aim of exposing both the strengths and the limitations of this active area of neuroscience research.},
author = {Niv, Yael and Schoenbaum, Geoffrey},
doi = {10.1016/j.tics.2008.03.006},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Niv, Schoenbaum - 2008 - Dialogues on prediction errors(2).pdf:pdf;:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Niv, Schoenbaum - 2008 - Dialogues on prediction errors(3).pdf:pdf},
issn = {1364-6613},
journal = {Trends in cognitive sciences},
keywords = {Artificial Intelligence,Association Learning,Brain,Brain: physiology,Discrimination Learning,Dopamine,Dopamine: physiology,Humans,Models,Neurological,Probability Learning,Psychological,Psychological Theory,Reinforcement (Psychology)},
month = {jul},
number = {7},
pages = {265--72},
pmid = {18567531},
title = {{Dialogues on prediction errors.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18567531},
volume = {12},
year = {2008}
}
@article{Notebaert2009,
abstract = {It is generally assumed that slowing after errors is a cognitive control effect reflecting more careful response strategies after errors. However, clinical data are not compatible with this explanation. We therefore consider two alternative explanations, one referring to the possibility of a persisting underlying problem and one on the basis of the low frequency of errors (orienting account). This latter hypothesis argues that infrequent events orient attention away from the task. Support for the orienting account was obtained in two experiments. Using a new experimental procedure, Experiment 1 demonstrated post-error slowing after infrequent errors and post-correct slowing after infrequent correct trials. In Experiment 2, slowing was observed following infrequent irrelevant tones replacing the feedback signals.},
author = {Notebaert, Wim and Houtman, Femke and Opstal, Filip Van and Gevers, Wim and Fias, Wim and Verguts, Tom},
doi = {10.1016/j.cognition.2009.02.002},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Notebaert et al. - 2009 - Post-error slowing an orienting account(2).pdf:pdf},
issn = {1873-7838},
journal = {Cognition},
keywords = {Adolescent,Attention,Attention: physiology,Cognition,Cognition: physiology,Feedback,Female,Humans,Male,Psychological,Psychomotor Performance,Psychomotor Performance: physiology,Reaction Time,Reaction Time: physiology,Self Concept,Young Adult},
month = {may},
number = {2},
pages = {275--9},
pmid = {19285310},
title = {{Post-error slowing: an orienting account.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19285310},
volume = {111},
year = {2009}
}
@article{Ogawa1990,
abstract = {Paramagnetic deoxyhemoglobin in venous blood is a naturally occurring contrast agent for magnetic resonance imaging (MRI). By accentuating the effects of this agent through the use of gradient-echo techniques in high fields, we demonstrate in vivo images of brain microvasculature with image contrast reflecting the blood oxygen level. This blood oxygenation level-dependent (BOLD) contrast follows blood oxygen changes induced by anesthetics, by insulin-induced hypoglycemia, and by inhaled gas mixtures that alter metabolic demand or blood flow. The results suggest that BOLD contrast can be used to provide in vivo real-time maps of blood oxygenation in the brain under normal physiological conditions. BOLD contrast adds an additional feature to magnetic resonance imaging and complements other techniques that are attempting to provide positron emission tomography-like measurements related to regional neural activity.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Ogawa, Seiji and Lee, Tso-Ming and Kay, Alan R and Tank, David W},
doi = {10.1073/pnas.87.24.9868},
eprint = {NIHMS150003},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Anatomy and Function/Ogawa et al. - 1990 - Brain magnetic resonance imaging with contrast dependent on blood oxygenation.pdf:pdf},
isbn = {0027-8424 (Print) 0027-8424 (Linking)},
issn = {0027-8424},
journal = {Proceedings of the National Academy of Sciences},
keywords = {Animals,Blood Flow Velocity,Brain,Brain: anatomy {\&} histology,Brain: physiology,Brain: physiopathology,Carbon Dioxide,Carbon Dioxide: blood,Cerebrovascular Circulation,Female,Hemoglobins,Hemoglobins: metabolism,Hypoglycemia,Hypoglycemia: physiopathology,Inbred Strains,Kinetics,Magnetic Resonance Imaging,Magnetic Resonance Imaging: methods,Models,Neurological,Oxygen,Oxygen: blood,Rats},
number = {24},
pages = {9868--9872},
pmid = {2124706},
title = {{Brain magnetic resonance imaging with contrast dependent on blood oxygenation.}},
url = {http://www.pnas.org/cgi/doi/10.1073/pnas.87.24.9868},
volume = {87},
year = {1990}
}
@article{Otto2015,
abstract = {Accounts of decision-making and its neural substrates have long posited the operation of separate, competing valuation systems in the control of choice behavior. Recent theoretical and experimental work suggest that this classic distinction between behaviorally and neurally dissociable systems for habitual and goal-directed (or more generally, automatic and controlled) choice may arise from two computational strategies for reinforcement learning (RL), called model-free and model-based RL, but the cognitive or computational processes by which one system may dominate over the other in the control of behavior is a matter of ongoing investigation. To elucidate this question, we leverage the theoretical framework of cognitive control, demonstrating that individual differences in utilization of goal-related contextual information--in the service of overcoming habitual, stimulus-driven responses--in established cognitive control paradigms predict model-based behavior in a separate, sequential choice task. The behavioral correspondence between cognitive control and model-based RL compellingly suggests that a common set of processes may underpin the two behaviors. In particular, computational mechanisms originally proposed to underlie controlled behavior may be applicable to understanding the interactions between model-based and model-free choice behavior.},
author = {Otto, A Ross and Skatova, Anya and Madlon-Kay, Seth and Daw, Nathaniel D},
doi = {10.1162/jocn_a_00709},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Otto et al. - 2015 - Cognitive control predicts use of model-based reinforcement learning(2).pdf:pdf},
issn = {1530-8898},
journal = {Journal of cognitive neuroscience},
month = {feb},
number = {2},
pages = {319--33},
pmid = {25170791},
title = {{Cognitive control predicts use of model-based reinforcement learning.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4387848{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {27},
year = {2015}
}
@book{Pavlov1927,
abstract = {The present volume is the first complete discussion of conditioned reflexes to be translated into one of the more familiar European languages. It contains 23 lectures, most of which were delivered in the spring of 1924 at the Military Medical Academy in Leningrad. After an initial discussion of historical background and of the technical methods employed, Pavlov discusses the following topics: the formation of conditioned reflexes by means of conditioned and direct stimuli; external and internal inhibition of conditioned reflexes; the analyzing and synthesizing activity of the cerebral hemisphere; irradiation and concentration of nervous processes in the cerebral cortex; mutual induction of excitation and inhibition; interaction of irradiation and concentration with induction; the cortex as a mosaic of functions; development of inhibition in the cortex under the influence of conditioned stimuli; internal inhibition and sleep as one and the same process with regard to their intimate mechanism; transition stages between the alert state and complete sleep-hypnotic stages; different types of nervous system; pathological disturbances of the cortex, result of functional and surgical interference; general characteristics of the present investigation and its special difficulties; discovery of certain errors necessitating the modification of some earlier interpretations; and the experimental results obtained with animals in their application to man. Attention is drawn to the similarity of the neuroses and psychoses to behavior observed in the dog during certain of the experiments. A bibliography is given of all papers published from Pavlov's laboratories upon the physiology of conditioned reflexes.},
address = {London},
author = {Pavlov, Ivan},
publisher = {Oxford Univ. Press},
title = {{Conditioned reflexes: an investigation of the physiological activity of the cerebral cortex.}},
year = {1927}
}
@article{Purcell2016,
author = {Purcell, Braden A and Kiani, Roozbeh},
doi = {10.1016/j.neuron.2015.12.027},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Purcell, Kiani - 2016 - Neural Mechanisms of Post-error Adjustments of Decision Policy in Parietal Cortex.pdf:pdf},
issn = {08966273},
journal = {Neuron},
number = {3},
pages = {658--671},
pmid = {26804992},
title = {{Neural Mechanisms of Post-error Adjustments of Decision Policy in Parietal Cortex}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0896627315011290},
volume = {89},
year = {2016}
}
@article{Rae2015,
abstract = {Communication between the prefrontal cortex and subcortical nuclei underpins the control and inhibition of behavior. However, the interactions in such pathways remain controversial. Using a stop-signal response inhibition task and functional imaging with analysis of effective connectivity, we show that the lateral prefrontal cortex influences the strength of communication between regions in the frontostriatal motor system. We compared 20 generative models that represented alternative interactions between the inferior frontal gyrus, presupplementary motor area (preSMA), subthalamic nucleus (STN), and primary motor cortex during response inhibition. Bayesian model selection revealed that during successful response inhibition, the inferior frontal gyrus modulates an excitatory influence of the preSMA on the STN, thereby amplifying the downstream polysynaptic inhibition from the STN to the motor cortex. Critically, the strength of the interaction between preSMA and STN, and the degree of modulation by the inferior frontal gyrus, predicted individual differences in participants' stopping performance (stop-signal reaction time). We then used diffusion-weighted imaging with tractography to assess white matter structure in the pathways connecting these three regions. The mean diffusivity in tracts between preSMA and the STN, and between the inferior frontal gyrus and STN, also predicted individual differences in stopping efficiency. Finally, we found that white matter structure in the tract between preSMA and STN correlated with effective connectivity of the same pathway, providing important cross-modal validation of the effective connectivity measures. Together, the results demonstrate the network dynamics and modulatory role of the prefrontal cortex that underpin individual differences in inhibitory control.},
author = {Rae, Charlotte L and Hughes, Laura E and Anderson, Michael C and Rowe, James B},
doi = {10.1523/JNEUROSCI.3093-13.2015},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rae et al. - 2015 - The Prefrontal Cortex Achieves Inhibitory Control by Facilitating Subcortical Motor Pathway Connectivity.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {diffusion mri tractography,dynamic causal modelling,inferior frontal gyrus,inhibition,presupplementary motor area,response,stop-signal task},
number = {2},
pages = {786--794},
pmid = {25589771},
title = {{The Prefrontal Cortex Achieves Inhibitory Control by Facilitating Subcortical Motor Pathway Connectivity}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.3093-13.2015},
volume = {35},
year = {2015}
}
@article{Ratcliff2015,
abstract = {Methods of fitting the diffusion model were examined with a focus on what the model can tell us about individual differences. Diffusion model parameters were obtained from the fits to data from 2 experiments and consistency of parameter values, individual differences, and practice effects were examined using different numbers of observations from each subject. Two issues were examined—first, what sizes of differences between groups can be obtained to distinguish between groups, and second, what sizes of differences would be needed to find individual subjects that had a deficit relative to a control group. The parameter values from the experiments provided ranges that were used in a simulation study to examine recovery of individual differences. This study used several diffusion model fitting programs, fitting methods, and published packages. In a second simulation study, 64 sets of simulated data from each of 48 sets of parameter values (spanning the range of typical values obtained from fits to data) were fit with the different methods, and biases and standard deviations in recovered model parameters were compared across methods. Finally, in a third simulation study, a comparison between a standard chi-square method and a hierarchical Bayesian method was performed. The results from these studies can be used as a starting point for selecting fitting methods, and as a basis for understanding the strengths and weaknesses of using diffusion model analyses to examine individual differences in clinical, neuropsychological, and educational testing. },
author = {Ratcliff, Roger and Childers, Russ},
doi = {10.1037/dec0000030},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Drift Diffusion/Ratcliff, Childers - 2015 - Individual differences and fitting methods for the two-choice diffusion model of decision making.pdf:pdf},
isbn = {2325-9965},
issn = {2325-9973},
journal = {Decision},
keywords = {10,1037,dec0000030,diffusion model,doi,dx,educational testing,http,individual differences,neuropsychological testing,org,response time,supp,supplemental materials},
number = {4},
pages = {237--279},
pmid = {26236754},
title = {{Individual differences and fitting methods for the two-choice diffusion model of decision making.}},
url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/dec0000030},
volume = {2},
year = {2015}
}
@article{Ratcliff2008,
abstract = {The diffusion decision model allows detailed explanations of behavior in two-choice discrimination tasks. In this article, the model is reviewed to show how it translates behavioral data-accuracy, mean response times, and response time distributions-into components of cognitive processing. Three experiments are used to illustrate experimental manipulations of three components: stimulus difficulty affects the quality of information on which a decision is based; instructions emphasizing either speed or accuracy affect the criterial amounts of information that a subject requires before initiating a response; and the relative proportions of the two stimuli affect biases in drift rate and starting point. The experiments also illustrate the strong constraints that ensure the model is empirically testable and potentially falsifiable. The broad range of applications of the model is also reviewed, including research in the domains of aging and neurophysiology.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Ratcliff, Roger and McKoon, Gail},
doi = {10.1162/neco.2008.12-06-420},
eprint = {NIHMS150003},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ratcliff, McKoon - 2008 - The diffusion decision model theory and data for two-choice decision tasks.pdf:pdf},
isbn = {0899-7667 (Print)$\backslash$n0899-7667 (Linking)},
issn = {0899-7667},
journal = {Neural computation},
number = {4},
pages = {873--922},
pmid = {18085991},
title = {{The diffusion decision model: theory and data for two-choice decision tasks.}},
volume = {20},
year = {2008}
}
@article{Ratcliff2016a,
abstract = {There is growing interest in diffusion models to represent the cognitive and neural processes of speeded decision making. Sequential-sampling models like the diffusion model have a long history in psychology. They view decision making as a process of noisy accumulation of evidence from a stimulus. The standard model assumes that evidence accumulates at a constant rate during the second or two it takes to make a decision. This process can be linked to the behaviors of populations of neurons and to theories of optimality. Diffusion models have been used successfully in a range of cognitive tasks and as psychometric tools in clinical research to examine individual differences. In this review, we relate the models to both earlier and more recent research in psychology.},
author = {Ratcliff, Roger and Smith, Philip L and Brown, Scott D and McKoon, Gail},
doi = {10.1016/j.tics.2016.01.007},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ratcliff et al. - 2016 - Diffusion Decision Model Current Issues and History(2).pdf:pdf},
issn = {1879307X},
journal = {Trends in Cognitive Sciences},
keywords = {Diffusion model,Nonstationarity,Optimality,Response time},
number = {4},
pages = {260--281},
pmid = {26952739},
title = {{Diffusion Decision Model: Current Issues and History}},
url = {http://dx.doi.org/10.1016/j.tics.2016.01.007},
volume = {20},
year = {2016}
}
@article{Ratcliff2010,
abstract = {The effects of aging and IQ on performance were examined in three two-choice tasks: numerosity discrimination, recognition memory, and lexical decision. The experimental data, accuracy, correct and error response times, and response time distributions, were well explained by Ratcliff's (1978) diffusion model. The components of processing identified by the model were compared across levels of IQ (ranging from 83 to 146) and age (college students, 60-74, and 75-90 year olds). Declines in performance with age were not significantly different for low compared to high IQ subjects. IQ but not age had large effects on the quality of the evidence that was obtained from a stimulus or memory, that is, the evidence upon which decisions were based. Applying the model to individual subjects, the components of processing identified by the model for individuals correlated across tasks. In addition, the model's predictions and the data were examined for the "worst performance rule", the finding that age and IQ have larger effects on slower responses than faster responses. {\textcopyright} 2009 Elsevier Inc. All rights reserved.},
author = {Ratcliff, Roger and Thapar, Anjali and McKoon, Gail},
doi = {10.1016/j.cogpsych.2009.09.001},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Drift Diffusion/Ratcliff, Thapar, McKoon - 2010 - Individual differences, aging, and IQ in two-choice tasks.pdf:pdf},
isbn = {00100285},
issn = {00100285},
journal = {Cognitive Psychology},
keywords = {Aging,Diffusion model,IQ,Individual differences,Reaction time},
number = {3},
pages = {127--157},
pmid = {19962693},
title = {{Individual differences, aging, and IQ in two-choice tasks}},
url = {http://dx.doi.org/10.1016/j.cogpsych.2009.09.001},
volume = {60},
year = {2010}
}
@article{Redgrave2008,
abstract = {The basal ganglia have been associated with processes of reinforcement learning. A strong line of supporting evidence comes from the recording of dopamine (DA) neurones in behaving monkeys. Unpredicted, biologically salient events, including rewards cause a stereotypic short-latency (70-100 ms), short-duration (100-200 ms) burst of DA activity - the phasic response. This response is widely considered to represent reward prediction errors used as teaching signals in appetitive learning to promote actions that will maximise future reward acquisition. For DA signalling to perform this function, sensory processing afferent to DA neurones should discriminate unpredicted reward-related events. However, the comparative response latencies of DA neurones and orienting gaze-shifts indicate that phasic DA responses are triggered by pre-attentive sensory processing. Consequently, in circumstances where biologically salient events are both spatially and temporally unpredictable, it is unlikely their identity will be known at the time of DA signalling. The limited quality of afferent sensory processing and the precise timing of phasic DA signals, suggests that they may play a less direct role in 'Law of Effect' appetitive learning. Rather, the 'time-stamp' nature of the phasic response, in conjunction with the other signals likely to be present in the basal ganglia at the time of phasic DA input, suggests it may reinforce the discovery of unpredicted sensory events for which the organism is responsible. Furthermore, DA-promoted repetition of preceding actions/movements should enable the system to converge on those aspects of context and behavioural output that lead to the discovery of novel actions.},
author = {Redgrave, Peter and Gurney, Kevin and Reynolds, John},
doi = {10.1016/j.brainresrev.2007.10.007},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Redgrave, Gurney, Reynolds - 2008 - What is reinforced by phasic dopamine signals.pdf:pdf;:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Redgrave, Gurney, Reynolds - 2008 - What is reinforced by phasic dopamine signals(2).pdf:pdf},
issn = {0165-0173},
journal = {Brain research reviews},
keywords = {Animals,Dopamine,Dopamine: physiology,Humans,Neural Pathways,Neural Pathways: physiology,Neurons,Neurons: physiology,Reinforcement (Psychology),Substantia Nigra,Substantia Nigra: cytology,Substantia Nigra: physiology},
month = {aug},
number = {2},
pages = {322--39},
pmid = {18055018},
title = {{What is reinforced by phasic dopamine signals?}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18055018},
volume = {58},
year = {2008}
}
@article{Redgrave1999,
abstract = {Unexpected stimuli which are behaviourally significant have the capacity to evoke a short latency, short duration burst of firing in mesencephalic dopamine neurones. An influential interpretation of the experimental data characterising this response proposes that dopamine neurones play a critical role in reinforcement learning by signalling errors in the prediction of future reward. In the present viewpoint we propose a different functional role for the short latency dopamine response in the mechanisms of associative learning. We suggest that the initial burst of dopaminergic firing may represent an essential component in the process of switching attentional and behavioural selections to unexpected, behaviourally important stimuli. This switching response could be a critical prerequisite for associative learning and may be part of a general short latency reaction, mediated by catecholamines, which prepares the organism to react appropriately to biologically significant events.},
author = {Redgrave, Peter and Prescott, Tony J and Gurney, Kevin},
doi = {10.1016/S0166-2236(98)01373-3},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Redgrave, Prescott, Gurney - 1999 - Is the short-latency dopamine response too short to signal reward error(2).pdf:pdf},
isbn = {0166-2236 (Print)},
issn = {01662236},
journal = {Trends in Neuroscience},
keywords = {Action Potentials,Animal,Animal: physiology,Animals,Association,Attention,Attention: physiology,Avoidance Learning,Avoidance Learning: physiology,Basal Ganglia,Basal Ganglia: physiology,Behavior,Catecholamines,Catecholamines: physiology,Conditioning,Dopamine,Dopamine: physiology,Exploratory Behavior,Humans,Learning,Learning: physiology,Mesencephalon,Mesencephalon: physiology,Models,Neurological,Operant,Operant: physiology,Psychological,Reaction Time,Reaction Time: physiology,Reinforcement (Psychology),Reward,Time Factors},
month = {apr},
number = {4},
pages = {146--151},
pmid = {10203849},
title = {{Is the short latency dopamine burst too short to signal reinforcement error?}},
volume = {22},
year = {1999}
}
@incollection{Rescorla1972,
address = {New York},
author = {Rescorla, Robert A and Wagner, Allan R},
booktitle = {Classical conditioning: current research and theory},
editor = {Black, A H and Prokasy, W F},
pages = {64--99},
publisher = {Appleton Century Crofts},
title = {{A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement}},
year = {1972}
}
@article{Ridderinkhof2004,
abstract = {Convergent evidence highlights the differential contributions of various regions of the prefrontal cortex in the service of cognitive control, but little is understood about how the brain determines and communicates the need to recruit cognitive control, and how such signals instigate the implementation of appropriate performance adjustments. Here we review recent progress from cognitive neuroscience in examining some of the main constituent processes of cognitive control as involved in dynamic decision making: goal-directed action selection, response activation and inhibition, performance monitoring, and reward-based learning. Medial frontal cortex is found to be involved in performance monitoring: evaluating outcome vis-a-vis expectancy, and detecting performance errors or conflicting response tendencies. Lateral and orbitofrontal divisions of prefrontal cortex are involved in subsequently implementing appropriate adjustments.},
author = {Ridderinkhof, K Richard and van den Wildenberg, Wery P M and Segalowitz, Sidney J and Carter, Cameron S},
doi = {10.1016/j.bandc.2004.09.016},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ridderinkhof et al. - 2004 - Neurocognitive mechanisms of cognitive control the role of prefrontal cortex in action selection, respon(2).pdf:pdf;:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ridderinkhof et al. - 2004 - Neurocognitive mechanisms of cognitive control the role of prefrontal cortex in action selection, respon(3).pdf:pdf},
issn = {0278-2626},
journal = {Brain and cognition},
keywords = {Animals,Cognition,Cognition: physiology,Decision Making,Decision Making: physiology,Goals,Haplorhini,Humans,Learning,Learning: physiology,Motivation,Prefrontal Cortex,Prefrontal Cortex: physiology,Psychomotor Performance,Psychomotor Performance: physiology,Reward},
month = {nov},
number = {2},
pages = {129--40},
pmid = {15518930},
title = {{Neurocognitive mechanisms of cognitive control: the role of prefrontal cortex in action selection, response inhibition, performance monitoring, and reward-based learning.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/15518930},
volume = {56},
year = {2004}
}
@article{Roiser2009,
abstract = {It has been suggested that some psychotic symptoms reﬂect ‘ aberrant salience ', related to dysfunctional reward learning. To test this hypothesis we investigated whether patients with schizophrenia},
author = {Roiser, Jonathan P and Stephan, Klaas E and den Ouden, Hanneke E M and Barnes, Tim R E and Friston, Karl J and Joyce, Eileen M},
doi = {10.1017/S0033291708003863},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Reinforcement Learning/Roiser et al. - 2009 - Do patients with schizophrenia exhibit aberrant salience.pdf:pdf},
isbn = {0033291708003},
issn = {0033-2917},
journal = {Psychological Medicine},
keywords = {aberrant salience,dopamine,psychosis,reinforcement,salience attribution test,schizophrenia},
number = {02},
pages = {199},
pmid = {18588739},
title = {{Do patients with schizophrenia exhibit aberrant salience?}},
url = {http://www.journals.cambridge.org/abstract{\_}S0033291708003863},
volume = {39},
year = {2009}
}
@article{Sabb2008,
abstract = {The human genome project has stimulated development of impressive repositories of biological knowledge at the genomic level and new knowledge bases are rapidly being developed in a 'bottom-up' fashion. In contrast, higher-level phenomics knowledge bases are underdeveloped, particularly with respect to the complex neuropsychiatric syndrome, symptom, cognitive, and neural systems phenotypes widely acknowledged as critical to advance molecular psychiatry research. This gap limits informatics strategies that could improve both the mining and representation of relevant knowledge, and help prioritize phenotypes for new research. Most existing structured knowledge bases also engage a limited set of contributors, and thus fail to leverage recent developments in social collaborative knowledge-building. We developed a collaborative annotation database to enable representation and sharing of empirical information about phenotypes important to neuropsychiatric research (www.Phenowiki.org). As a proof of concept, we focused on findings relevant to 'cognitive control', a neurocognitive construct considered important to multiple neuropsychiatric syndromes. Currently this knowledge base tabulates empirical findings about heritabilities and measurement properties of specific cognitive task and rating scale indicators (n=449 observations). It is hoped that this new open resource can serve as a starting point that enables broadly collaborative knowledge-building, and help investigators select and prioritize endophenotypes for translational research.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Sabb, Fred W and Bearden, Carrie E and Glahn, David C and Parker, D Stott and Freimer, Nelson and Bilder, Robert M},
doi = {10.1038/sj.mp.4002124},
eprint = {NIHMS150003},
isbn = {1359-4184},
issn = {1476-5578},
journal = {Molecular psychiatry},
keywords = {Cognition,Cognition: physiology,Computational Biology,Cooperative Behavior,Database Management Systems,Databases as Topic,Humans,Knowledge Bases,Phenotype},
number = {4},
pages = {350--60},
pmid = {18180765},
title = {{A collaborative knowledge base for cognitive phenomics.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18180765},
volume = {13},
year = {2008}
}
@article{Schiffer2014,
abstract = {Humans reliably learn which actions lead to rewards. One prominent question is how credit is assigned to environmental stimuli that are acted upon. Recent functional magnetic resonance imaging (fMRI) studies have provided evidence that representations of rewarded stimuli are activated upon reward delivery, providing possible eligibility traces for credit assignment. Our study sought evidence of postreward activation in sensory cortices satisfying two conditions of instrumental learning: postreward activity should reflect the stimulus category that preceded reward (stimulus specificity), and should occur only if the stimulus was acted on to obtain reward (task dependency). Our experiment implemented two tasks in the fMRI scanner. The first was a perceptual decision-making task on degraded face and house stimuli. Stimulus specificity was evident as rewards activated the sensory cortices associated with face versus house perception more strongly after face versus house decisions, respectively, particularly in the fusiform face area. Stimulus specificity was further evident in a psychophysiological interaction analysis wherein face-sensitive areas correlated with nucleus accumbens activity after face-decision rewards, whereas house-sensitive areas correlated with nucleus accumbens activity after house-decision rewards. The second task required participants to make an instructed response. The criterion of task dependency was fulfilled as rewards after face versus house responses activated the respective association cortices to a larger degree when faces and houses were relevant to the performed task. Our study is the first to show that postreward sensory cortex activity meets these two key criteria of credit assignment, and does so independently from bottom-up perceptual processing.},
author = {Schiffer, Anne-Marike and Muller, Timothy and Yeung, Nick and Waszak, Florian},
doi = {10.1523/JNEUROSCI.1640-14.2014},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schiffer et al. - 2014 - Reward Activates Stimulus-Specific and Task-Dependent Representations in Visual Association Cortices.pdf:pdf},
isbn = {1529-2401},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {credit assignment,fmri,reward-related learning,stimulus-specific postreward activation},
number = {47},
pages = {15610--15620},
pmid = {25411489},
title = {{Reward Activates Stimulus-Specific and Task-Dependent Representations in Visual Association Cortices}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.1640-14.2014},
volume = {34},
year = {2014}
}
@article{Schiffler2016,
abstract = {Negative feedback after an action in a cognitive task can lead to devaluing that action on future trials as well as to more cautious responding when encountering that same choice again. These phenomena have been explored in the past by reinforcement learning theories and cognitive control accounts, respectively. Yet, how cognitive control interacts with value updating to give rise to adequate adaptations under uncertainty is less clear. In this fMRI study, we investigated cognitive control-based behavioral adjustments during a probabilistic reinforcement learning task and studied their influence on performance in a later test phase in which the learned value of items is tested. We provide support for the idea that functionally relevant and memory-reliant behavioral adjustments in the form of posterror slowing during reinforcement learning are associated with test performance. Adjusting response speed after negative feedback was correlated with BOLD activity in right inferior frontal gyrus and bilateral middle occipital cortex during the event of receiving the feedback. Bilateral middle occipital cortex activity overlapped partly with activity reflecting feedback deviance from expectations as measured by unsigned prediction error. These results suggest that cognitive control and feature processing cortical regions interact to implement feedback-congruent adaptations beneficial to learning.},
annote = {doi: 10.1162/jocn{\_}a{\_}00987},
author = {Schiffler, Bj{\"{o}}rn C and Almeida, Rita and Granqvist, Mathias and Bengtsson, Sara L},
doi = {10.1162/jocn_a_00987},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schiffler et al. - 2016 - Memory-reliant Posterror Slowing Is Associated with Successful Learning and Fronto-occipital Activity.pdf:pdf},
issn = {1530-8898 (Electronic)},
journal = {Journal of cognitive neuroscience},
month = {may},
number = {10},
pages = {1539--1552},
pmid = {27243614},
title = {{Memory-reliant Posterror Slowing Is Associated with Successful Learning and Fronto-occipital Activity.}},
url = {http://dx.doi.org/10.1162/jocn{\_}a{\_}00987},
volume = {28},
year = {2016}
}
@article{Schiffler2017,
author = {Schiffler, Bj{\"{o}}rn C and Bengtsson, Sara L and Lundqvist, Daniel},
doi = {10.3389/fpsyg.2017.01077},
file = {:C$\backslash$:/Dropbox/PhD/Articles/own/Schiffler, Bengtsson, Lundqvist - 2017 - The Sustained Influence of an Error on Future Decision-Making.pdf:pdf},
issn = {1664-1078},
journal = {Frontiers in Psychology},
pages = {1077},
title = {{The Sustained Influence of an Error on Future Decision-Making}},
url = {http://journal.frontiersin.org/article/10.3389/fpsyg.2017.01077/full},
volume = {8},
year = {2017}
}
@article{Schultz1997,
abstract = {The capacity to predict future events permits a creature to detect, model, and manipulate the causal structure of its interactions with its environment. Behavioral experiments suggest that learning is driven by changes in the expectations about future salient events such as rewards and punishments. Physiological work has recently complemented these studies by identifying dopaminergic neurons in the primate whose fluctuating output apparently signals changes or errors in the predictions of future salient and rewarding events. Taken together, these findings can be understood through quantitative theories of adaptive optimizing control.},
archivePrefix = {arXiv},
arxivId = {NIHMS150003},
author = {Schultz, Wolfram and Dayan, Peter and Montague, P Read},
doi = {10.1126/science.275.5306.1593},
eprint = {NIHMS150003},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schultz, Dayan, Montague - 1997 - A neural substrate of prediction and reward(2).pdf:pdf;:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schultz, Dayan, Montague - 1997 - A neural substrate of prediction and reward(3).pdf:pdf},
isbn = {0036-8075},
issn = {0036-8075},
journal = {Science},
keywords = {Algorithms,Animals,Computer Simulation,Conditioning (Psychology),Cues,Dopamine,Dopamine: physiology,Learning,Mesencephalon,Mesencephalon: physiology,Models,Neurological,Neurons,Neurons: physiology,Rats,Reward},
month = {mar},
number = {5306},
pages = {1593--1599},
pmid = {9054347},
title = {{A Neural Substrate of Prediction and Reward}},
url = {http://www.sciencemag.org/cgi/doi/10.1126/science.275.5306.1593},
volume = {275},
year = {1997}
}
@article{Seymour2004,
abstract = {The ability to use environmental stimuli to predict impending harm is critical for survival. Such predictions should be available as early as they are reliable. In pavlovian conditioning, chains of successively earlier predictors are studied in terms of higher-order relationships, and have inspired computational theories such as temporal difference learning. However, there is at present no adequate neurobiological account of how this learning occurs. Here, in a functional magnetic resonance imaging (fMRI) study of higher-order aversive conditioning, we describe a key computational strategy that humans use to learn predictions about pain. We show that neural activity in the ventral striatum and the anterior insula displays a marked correspondence to the signals for sequential learning predicted by temporal difference models. This result reveals a flexible aversive learning process ideally suited to the changing and uncertain nature of real-world environments. Taken with existing data on reward learning, our results suggest a critical role for the ventral striatum in integrating complex appetitive and aversive predictions to coordinate behaviour.},
author = {Seymour, Ben and O'Doherty, John P and Dayan, Peter and Koltzenburg, Martin and Jones, Anthony K and Dolan, Raymond J and Friston, Karl J and Frackowiak, Richard S},
doi = {10.1038/nature02581},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Seymour et al. - 2004 - Temporal difference models describe higher-order learning in humans.pdf:pdf},
isbn = {1476-4687 (Electronic)$\backslash$r0028-0836 (Linking)},
issn = {0028-0836},
journal = {Nature},
number = {6992},
pages = {664--667},
pmid = {15190354},
title = {{Temporal difference models describe higher-order learning in humans}},
url = {http://www.nature.com/doifinder/10.1038/nature02581},
volume = {429},
year = {2004}
}
@article{Siegert2014,
abstract = {Error monitoring is essential for optimizing motor behavior. It has been linked to the medial frontal cortex, in particular to the anterior midcingulate cortex (aMCC). The aMCC subserves its performance-monitoring function in interaction with the basal ganglia (BG) circuits, as has been demonstrated in patients suffering from BG lesions or from Parkinson's disease (PD). The subthalamic nucleus (STN) has been assumed an integrative structure for emotional, cognitive and motor processing. Error-related behavioral adaptation such as post-error slowing has been linked to motor inhibition involving activation of an inhibitory network including the STN. However, direct involvement of the STN in error monitoring and post-error behavioral adjustment has not yet been demonstrated.Here, we used simultaneous scalp electroencephalogram (EEG) and local field potential (LFP) recordings from the BG in 17 patients undergoing deep brain stimulation (DBS) for PD to investigate error-related evoked activity in the human STN, its relation to post-error behavioral adjustment and the influence of dopamine during the performance of a speeded flanker task.We found an error-related positive deflection (STN-Pe) in the STN-LFP 260-450msec after error commission. Importantly, the STN-Pe amplitude was larger in trials with post-error slowing compared to trials with post-error speeding. There was no overall effect of dopamine on error processing. Subgroup analysis revealed a higher error rate (ER) in younger patients with earlier disease onset ON medication compared to OFF medication (and vice versa in the older patient group), which was associated with modulatory effects of the early cortical error-related negativity (ERN) and late STN-Pe. The late error-related STN-Pe that is associated with post-error reaction time (RT) adjustments supports the notion that post-error slowing is implemented by motor inhibition involving the STN. Further, the modulation of behavioral performance by dopaminergic therapy depending on patients' age may suggest a dopamine overdose effect in patients with earlier onset of PD.},
author = {Siegert, Sandy and {Herrojo Ruiz}, Maria and Br{\"{u}}cke, Christof and Huebl, Julius and Schneider, Gerd Helge and Ullsperger, Markus and K{\"{u}}hn, Andrea A.},
doi = {10.1016/j.cortex.2013.12.008},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Siegert et al. - 2014 - Error signals in the subthalamic nucleus are related to post-error slowing in patients with Parkinson's disea(3).pdf:pdf},
isbn = {1973-8102 (Electronic)$\backslash$n0010-9452 (Linking)},
issn = {19738102},
journal = {Cortex},
keywords = {Dopamine,Error processing,Error-related negativity,ON/OFF,Post-error slowing,Subthalamic nucleus},
month = {jan},
pages = {103--120},
pmid = {24525245},
title = {{Error signals in the subthalamic nucleus are related to post-error slowing in patients with Parkinson's disease}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24525245},
volume = {60},
year = {2014}
}
@article{Silver2017,
abstract = {A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains. Recently, AlphaGo became the first program to defeat a world champion in the game of Go. The tree search in AlphaGo evaluated positions and selected moves using deep neural networks. These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play. Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules. AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo's own move selections and also the winner of AlphaGo's games. This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration. Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100–0 against the previously published, champion-defeating AlphaGo.},
author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
doi = {10.1038/nature24270},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Machine Learning/Silver et al. - 2017 - Article Mastering the game of Go without human knowledge.pdf:pdf},
isbn = {3013372370},
issn = {0028-0836},
journal = {Nature},
number = {7676},
pages = {354--359},
pmid = {29052630},
title = {{Mastering the game of Go without human knowledge}},
url = {http://www.nature.com/doifinder/10.1038/nature24270},
volume = {550},
year = {2017}
}
@article{Skinner1935,
author = {Skinner, Burrhus F},
doi = {10.1080/00221309.1935.9920087},
isbn = {0022-1309$\backslash$r1940-0888},
issn = {0022-1309},
journal = {The Journal of General Psychology},
number = {1},
pages = {40--65},
title = {{The Generic Nature of the Concepts of Stimulus and Response}},
volume = {12},
year = {1935}
}
@article{Smittenaar2013,
abstract = {Human choice behavior often reflects a competition between inflexible computationally efficient control on the one hand and a slower more flexible system of control on the other. This distinction is well captured by model-free and model-based reinforcement learning algorithms. Here, studying human subjects, we show it is possible to shift the balance of control between these systems by disruption of right dorsolateral prefrontal cortex, such that participants manifest a dominance of the less optimal model-free control. In contrast, disruption of left dorsolateral prefrontal cortex impaired model-based performance only in those participants with low working memory capacity},
author = {Smittenaar, Peter and FitzGerald, Thomas H B and Romei, Vincenzo and Wright, Nicholas D. and Dolan, Raymond J.},
doi = {10.1016/j.neuron.2013.08.009},
isbn = {1097-4199 (Electronic) 0896-6273 (Linking)},
issn = {08966273},
journal = {Neuron},
number = {4},
pages = {914--919},
pmid = {24206669},
title = {{Disruption of Dorsolateral Prefrontal Cortex Decreases Model-Based in Favor of Model-free Control in Humans}},
url = {http://dx.doi.org/10.1016/j.neuron.2013.08.009},
volume = {80},
year = {2013}
}
@article{Steinhauser2017,
abstract = {{\textcopyright} 2016 American Psychological Association. Posterror slowing (PES) refers to an increased response time following errors. While PES has traditionally been attributed to control adjustments, recent evidence suggested that PES reflects interference. The present study investigated the hypothesis that control and interference represent 2 components of PES that differ with respect to their time course and task-specificity. To this end, we investigated PES in a dual-task paradigm in which participants had to classify colors and tones that were separated by a variable stimulus onset asynchrony (SOA). Errors in the color task caused PES both in the tone task of the same trial and the color task of the subsequent trial. However, while the former effect disappeared with an increasing SOA, the latter effect was independent of SOA and lasted for several trials. This suggests that errors simultaneously induce task-unspecific, transient PES reflecting interference and task-specific, more long-lasting PES reflecting control adjustments.},
author = {Steinhauser, Marco and Ernst, Benjamin and Ibald, Kevin W},
doi = {10.1037/xlm0000329},
issn = {02787393},
journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
keywords = {action outcomes is an,actions,cognitive control,dual tasking,error monitoring,important,mance monitoring assume that,performance,posterror slowing,prerequisite for achieving optimal,the continuous monitoring of,the detection of erroneous,theories of perfor-},
number = {4},
pages = {653--659},
title = {{Isolating component processes of posterror slowing with the psychological refractory period paradigm}},
volume = {43},
year = {2017}
}
@article{Storsve2014,
abstract = {Human cortical thickness and surface area are genetically independent, emerge through different neurobiological events during development, and are sensitive to different clinical conditions. However, the relationship between changes in the two over time is unknown. Additionally, longitudinal studies have almost invariably been restricted to older adults, precluding the delineation of adult life span trajectories of change in cortical structure. In this longitudinal study, we investigated changes in cortical thickness, surface area, and volume after an average interval of 3.6 years in 207 well screened healthy adults aged 23-87 years. We hypothesized that the relationships among metrics are dynamic across the life span, that the primary contributor to cortical volume reductions in aging is cortical thinning, and that magnitude of change varies with age and region. Changes over time were seen in cortical area (mean annual percentage change [APC], -0.19), thickness (APC, -0.35), and volume (APC, -0.51) in most regions. Volume changes were primarily explained by changes in thickness rather than area. A negative relationship between change in thickness and surface area was found across several regions, where more thinning was associated with less decrease in area, and vice versa. Accelerating changes with increasing age was seen in temporal and occipital cortices. In contrast, decelerating changes were seen in prefrontal and anterior cingulate cortices. In conclusion, a dynamic relationship between cortical thickness and surface area changes exists throughout the adult life span. The mixture of accelerating and decelerating changes further demonstrates the importance of studying these metrics across the entire adult life span.},
author = {Storsve, Andreas B and Fjell, Anders M and Tamnes, Christian K and Westlye, Lars T and Overbye, Knut and Aasland, Hilde W and Walhovd, Kristine B},
doi = {10.1523/JNEUROSCI.0391-14.2014},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Anatomy and Function/Storsve et al. - 2014 - Differential Longitudinal Changes in Cortical Thickness, Surface Area and Volume across the Adult Life Span Regi.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$r0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {aging,area,cortex,thickness,trajectory,volume},
number = {25},
pages = {8488--8498},
pmid = {24948804},
title = {{Differential Longitudinal Changes in Cortical Thickness, Surface Area and Volume across the Adult Life Span: Regions of Accelerating and Decelerating Change}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.0391-14.2014},
volume = {34},
year = {2014}
}
@article{Sutton1988,
abstract = {This article introduces a class of incremental learning procedures spe-cialized for prediction that is, for using past experience with an incompletely known system to predict its future behavior. Whereas conventional prediction-learning methods assign credit by means of the difference between predicted and actual out-comes, tile new methods assign credit by means of the difference between temporally successive predictions. Although such temporal-difference method{\~{}} have been used in Samuel's checker player, Holland's bucket brigade, and the author's Adaptive Heuris-tic Critic, they have remained poorly understood. Here we prove their convergence and optimality for special cases and relate them to supervised-learning methods. For most real-world prediction problems, telnporal-differenee methods require less mem-ory and less peak computation than conventional methods and they produce more accurate predictions. We argue that most problems to which supervised learning is currently applied are really prediction problems of the sort to which temporal-difference methods can be applied to advantage.},
author = {Sutton, Richard S},
doi = {10.1007/BF00115009},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Reinforcement Learning/Sutton - 1988 - Learning to Predict by the Methods of Temporal Differences.pdf:pdf},
isbn = {0885-6125},
issn = {15730565},
journal = {Machine Learning},
keywords = {Incremental learning,connectionism,credit assignment,evaluation functions,prediction},
number = {1},
pages = {9--44},
pmid = {22182453},
title = {{Learning to Predict by the Methods of Temporal Differences}},
volume = {3},
year = {1988}
}
@incollection{Sutton1990,
address = {Cambridge},
author = {Sutton, Richard S and Barto, Andrew G},
booktitle = {Learning and Computational Neuroscience: Foundations of Adaptive Networks},
doi = {1991-97439-012},
editor = {Gabriel, M and Moore, J},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sutton, Barto - 1990 - Time-Derivative Models of Pavlovian Reinforcement.pdf:pdf},
isbn = {0262071029},
pages = {497--537},
publisher = {MIT Press},
title = {{Time-Derivative Models of Pavlovian Reinforcement}},
year = {1990}
}
@book{Sutton1998,
abstract = {Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives when interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the key ideas and algorithms of reinforcement learning. Their discussion ranges from the history of the field's intellectual foundations to the most recent developments and applications. The only necessary mathematical background is familiarity with elementary concepts of probability.The book is divided into three parts. Part I defines the reinforcement learning problem in terms of Markov decision processes. Part II provides basic solution methods: dynamic programming, Monte Carlo methods, and temporal-difference learning. Part III presents a unified view of the solution methods and incorporates artificial neural networks, eligibility traces, and planning; the two final chapters present case studies and consider the future of reinforcement learning.},
address = {Cambridge},
author = {Sutton, Richard S and Barto, Andrew G},
isbn = {9780262193986},
publisher = {MIT Press},
title = {{Reinforcement Learning: An Introduction}},
year = {1998}
}
@article{Tabibnia2011,
abstract = {Psychological and neurocognitive studies have suggested that different kinds of self-control may share a common psychobiological component. If this is true, performance in affective and nonaffective inhibitory control tasks in the same individuals should be correlated and should rely upon integrity of this region. To test this hypothesis, we acquired high-resolution magnetic resonance images from 44 healthy and 43 methamphetamine-dependent subjects. Individuals with methamphetamine dependence were tested because of prior findings that they suffer inhibitory control deficits. Gray matter structure of the inferior frontal gyrus was assessed using voxel-based morphometry. Subjects participated in tests of motor and affective inhibitory control (stop-signal task and emotion reappraisal task, respectively); and methamphetamine-dependent subjects provided self-reports of their craving for methamphetamine. Performance levels on the two inhibitory control tasks were correlated with one another and with gray matter intensity in the right pars opercularis region of the inferior frontal gyrus in healthy subjects. Gray matter intensity of this region was also correlated with methamphetamine craving. Compared with healthy subjects, methamphetamine-dependent subjects exhibited lower gray matter intensity in this region, worse motor inhibitory control, and less success in affect regulation. These findings suggest that self-control in different psychological domains involves acommonsubstrate in the right pars opercularis, and that successful self-control depends on integrity of this substrate.},
author = {Tabibnia, Golnaz and Monterosso, John R and Baicy, Kate and Aron, Adam R and Poldrack, Russell A and Chakrapani, Shruthi and Lee, Buyean and London, Edythe D},
doi = {10.1523/JNEUROSCI.2859-10.2011},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Cognitive Control/Tabibnia et al. - 2011 - Different Forms of Self-Control Share a Neurocognitive Substrate.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$n0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
number = {13},
pages = {4805--4810},
pmid = {21451018},
title = {{Different Forms of Self-Control Share a Neurocognitive Substrate}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2859-10.2011},
volume = {31},
year = {2011}
}
@article{Thompson2017,
author = {Thompson, William Hedley and Brantefors, Per and Fransson, Peter},
doi = {10.1162/netn_a_00011},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Dynamic Functional Connectivity/Thompson, Brantefors, Fransson - 2017 - From static to temporal network theory - applications to functional brain connectivity.pdf:pdf},
journal = {Network Neuroscience},
keywords = {author contributions,connectome,dynamic functional connectivity,functional,pb,pf designed the study,pf revised the paper,resting-state,temporal network theory,temporal networks,the paper,wht,wht and pf wrote,wht wrote all code},
number = {2},
pages = {69--99},
title = {{From static to temporal network theory - applications to functional brain connectivity}},
volume = {1},
year = {2017}
}
@book{Thorndike1911,
author = {Thorndike, Edward L},
publisher = {Macmillan},
title = {{Animal intelligence: Experimental studies}},
year = {1911}
}
@article{Ullsperger2016,
abstract = {After errors, decision boundaries change, which results in post-error slowing of decisions. Purcell and Kiani (2016) report simultaneously decreased sensitivity to sensory information counteracts post-error increases in accuracy. Early post-error adjustments reflect a general orienting reflex rather than goal-directed adaptation.},
author = {Ullsperger, Markus and Danielmeier, Claudia},
doi = {10.1016/j.neuron.2016.01.035},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ullsperger, Danielmeier - 2016 - Reducing Speed and Sight How Adaptive Is Post-Error Slowing.pdf:pdf},
issn = {10974199},
journal = {Neuron},
number = {3},
pages = {430--432},
pmid = {26844827},
title = {{Reducing Speed and Sight: How Adaptive Is Post-Error Slowing?}},
url = {http://dx.doi.org/10.1016/j.neuron.2016.01.035},
volume = {89},
year = {2016}
}
@article{Ullsperger2014,
abstract = {Successful goal-directed behavior requires not only correct action selection, planning, and execution but also the ability to flexibly adapt behavior when performance problems occur or the environment changes. A prerequisite for determining the necessity, type, and magnitude of adjustments is to continuously monitor the course and outcome of one's actions. Feedback-control loops correcting deviations from intended states constitute a basic functional principle of adaptation at all levels of the nervous system. Here, we review the neurophysiology of evaluating action course and outcome with respect to their valence, i.e., reward and punishment, and initiating short- and long-term adaptations, learning, and decisions. Based on studies in humans and other mammals, we outline the physiological principles of performance monitoring and subsequent cognitive, motivational, autonomic, and behavioral adaptation and link them to the underlying neuroanatomy, neurochemistry, psychological theories, and computational models. We provide an overview of invasive and noninvasive systemic measures, such as electrophysiological, neuroimaging, and lesion data. We describe how a wide network of brain areas encompassing frontal cortices, basal ganglia, thalamus, and monoaminergic brain stem nuclei detects and evaluates deviations of actual from predicted states indicating changed action costs or outcomes. This information is used to learn and update stimulus and action values, guide action selection, and recruit adaptive mechanisms that compensate errors and optimize goal achievement.},
author = {Ullsperger, Markus and Danielmeier, Claudia and Jocham, Gerhard},
doi = {10.1152/physrev.00041.2012},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ullsperger, Danielmeier, Jocham - 2014 - Neurophysiology of performance monitoring and adaptive behavior(2).pdf:pdf},
issn = {1522-1210},
journal = {Physiological reviews},
keywords = {Adaptation, Psychological,Adaptation, Psychological: physiology,Animals,Behavior,Behavior: physiology,Brain,Brain: physiology,Humans,Learning,Learning: physiology,Motivation,Motivation: physiology,Reward},
month = {jan},
number = {1},
pages = {35--79},
pmid = {24382883},
title = {{Neurophysiology of performance monitoring and adaptive behavior.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/24382883},
volume = {94},
year = {2014}
}
@article{VandenBos2012,
abstract = {During development, children improve in learning from feedback to adapt their behavior. However, it is still unclear which neural mechanisms might underlie these developmental changes. In the current study, we used a reinforcement learning model to investigate neurodevelopmental changes in the representation and processing of learning signals. Sixty-seven healthy volunteers between ages 8 and 22 (children: 8-11 years, adolescents: 13-16 years, and adults: 18-22 years) performed a probabilistic learning task while in a magnetic resonance imaging scanner. The behavioral data demonstrated age differences in learning parameters with a stronger impact of negative feedback on expected value in children. Imaging data revealed that the neural representation of prediction errors was similar across age groups, but functional connectivity between the ventral striatum and the medial prefrontal cortex changed as a function of age. Furthermore, the connectivity strength predicted the tendency to alter expectations after receiving negative feedback. These findings suggest that the underlying mechanisms of developmental changes in learning are not related to differences in the neural representation of learning signals per se but rather in how learning signals are used to guide behavior and expectations.},
author = {{Van Den Bos}, Wouter and Cohen, Michael X and Kahnt, Thorsten and Crone, Eveline A},
doi = {10.1093/cercor/bhr198},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/van den Bos et al. - 2012 - Striatum-medial prefrontal cortex connectivity predicts developmental changes in reinforcement learning(2).pdf:pdf},
isbn = {1047-3211},
issn = {10473211},
journal = {Cerebral Cortex},
keywords = {brain maturation,development,fMRI,functional connectivity,reinforcement learning},
month = {jun},
number = {6},
pages = {1247--1255},
pmid = {21817091},
title = {{Striatum-medial prefrontal cortex connectivity predicts developmental changes in reinforcement learning}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/21817091},
volume = {22},
year = {2012}
}
@article{Volkow2010,
abstract = {Loss of control over drug taking is considered a hallmark of addiction and is critical in relapse. Dysfunction of frontal brain regions involved with inhibitory control may underlie this behavior. We evaluated whether addicted subjects when instructed to purposefully control their craving responses to drug-conditioned stimuli can inhibit limbic brain regions implicated in drug craving. We used PET and 2-deoxy-2[18F]fluoro-d-glucose to measure brain glucose metabolism (marker of brain function) in 24 cocaine abusers who watched a cocaine-cue video and compared brain activation with and without instructions to cognitively inhibit craving. A third scan was obtained at baseline (without video). Statistical parametric mapping was used for analysis and corroborated with regions of interest. The cocaine-cue video increased craving during the no-inhibition condition (pre 3 ?? 3, post 6 ?? 3; p {\textless} 0.001) but not when subjects were instructed to inhibit craving (pre 3 ?? 2, post 3 ?? 3). Comparisons with baseline showed visual activation for both cocaine-cue conditions and limbic inhibition (accumbens, orbitofrontal, insula, cingulate) when subjects purposefully inhibited craving (p {\textless} 0.001). Comparison between cocaine-cue conditions showed lower metabolism with cognitive inhibition in right orbitofrontal cortex and right accumbens (p {\textless} 0.005), which was associated with right inferior frontal activation (r = - 0.62, p {\textless} 0.005). Decreases in metabolism in brain regions that process the predictive (nucleus accumbens) and motivational value (orbitofrontal cortex) of drug-conditioned stimuli were elicited by instruction to inhibit cue-induced craving. This suggests that cocaine abusers may retain some ability to inhibit craving and that strengthening fronto-accumbal regulation may be therapeutically beneficial in addiction.},
author = {Volkow, Nora D and Fowler, Joanna S and Wang, Gene Jack and Telang, Frank and Logan, Jean and Jayne, Millard and Ma, Yeming and Pradhan, Kith and Wong, Christopher and Swanson, James M},
doi = {10.1016/j.neuroimage.2009.10.088},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Volkow et al. - 2010 - Cognitive control of drug craving inhibits brain reward regions in cocaine abusers.pdf:pdf},
isbn = {1095-9572 (Electronic)},
issn = {10538119},
journal = {NeuroImage},
keywords = {Brain imaging,Cingulate gyrus,Cognitive inhibition,Conditioned responses,Insula,Nucleus accumbens,Orbitofrontal cortex},
number = {3},
pages = {2536--2543},
pmid = {19913102},
title = {{Cognitive control of drug craving inhibits brain reward regions in cocaine abusers}},
url = {http://dx.doi.org/10.1016/j.neuroimage.2009.10.088},
volume = {49},
year = {2010}
}
@article{Helmholtz1850,
author = {von Helmholtz, Hermann},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Drift Diffusion/Messungen {\"{u}}ber den zeitlichen Verlauf der Zuckung animalischer Muskeln und die F.pdf:pdf},
journal = {Archiv f{\"{u}}r Anatomie, Physiologie und wissenschaftliche Medicin},
pages = {276--364},
title = {{Messungen {\"{u}}ber den zeitlichen Verlauf der Zuckung animalischer Muskeln und die Fortpflanzungsgeschwindigkeit der Reizung in den Nerven}},
year = {1850}
}
@article{Voon2015,
abstract = {Why do we repeat choices that we know are bad for us? Decision making is characterized by the parallel engagement of two distinct systems, goal-directed and habitual, thought to arise from two computational learning mechanisms, model-based and model-free. The habitual system is a candidate source of pathological fixedness. Using a decision task that measures the contribution to learning of either mechanism, we show a bias towards model-free (habit) acquisition in disorders involving both natural (binge eating) and artificial (methamphetamine) rewards, and obsessive-compulsive disorder. This favoring of model-free learning may underlie the repetitive behaviors that ultimately dominate in these disorders. Further, we show that the habit formation bias is associated with lower gray matter volumes in caudate and medial orbitofrontal cortex. Our findings suggest that the dysfunction in a common neurocomputational mechanism may underlie diverse disorders involving compulsion.},
author = {Voon, Valerie and Derbyshire, Katherine and R{\"{u}}ck, Christian and Irvine, Michael A and Worbe, Yulia and Enander, Jesper and Schreiber, Liana R N and Gillan, Claire and Fineberg, Naomi and Sahakian, Barbara J and Robbins, Trevor W and Harrison, Neil A and Wood, Jonathan and Daw, Nathaniel D and Dayan, Peter and Grant, Jon E and Bullmore, Edward T},
doi = {10.1038/mp.2014.44},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Voon et al. - 2014 - Disorders of compulsivity a common bias towards learning habits.pdf:pdf},
isbn = {1476-5578 (Electronic)$\backslash$r1359-4184 (Linking)},
issn = {1359-4184},
journal = {Molecular Psychiatry},
number = {3},
pages = {345--352},
pmid = {24840709},
title = {{Disorders of compulsivity: a common bias towards learning habits}},
url = {http://www.nature.com/doifinder/10.1038/mp.2014.44},
volume = {20},
year = {2015}
}
@phdthesis{Watkins1989,
author = {Watkins, Christopher J C H},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Reinforcement Learning/new{\_}thesis.pdf:pdf},
school = {King's College, Cambridge},
title = {{Learning from Delayed Rewards}},
type = {Doctoral Dissertation},
year = {1989}
}
@article{Watkins1992,
abstract = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states. This paper presents and proves in detail a convergence theorem for Q,-learning based on that outlined in Watkins (1989). We show that Q-learning converges to the optimum action-values with probability 1 so long as all actions are repeatedly sampled in all states and the action-values are represented discretely. We also sketch extensions to the cases of non-discounted, but absorbing, Markov environments, and where many Q values can be changed each iteration, rather than just one.},
archivePrefix = {arXiv},
arxivId = {1412.3409},
author = {Watkins, Christopher J C H and Dayan, Peter},
doi = {10.1023/A:1022676722315},
eprint = {1412.3409},
file = {:C$\backslash$:/Dropbox/PhD/Articles/Reinforcement Learning/Watkins, Dayan - 1992 - Technical Note Q-Learning.pdf:pdf},
isbn = {978-1-4613-6608-9},
issn = {15730565},
journal = {Machine Learning},
keywords = {(Formula presented.)-learning,asynchronous dynamic programming,reinforcement learning,temporal differences},
number = {3},
pages = {279--292},
pmid = {7761831},
title = {{Technical Note: Q-Learning}},
volume = {8},
year = {1992}
}
@article{Wiecki2013,
abstract = {The diffusion model is a commonly used tool to infer latent psychological processes underlying decision-making, and to link them to neural mechanisms based on response times. Although efficient open source software has been made available to quantitatively fit the model to data, current estimation methods require an abundance of response time measurements to recover meaningful parameters, and only provide point estimates of each parameter. In contrast, hierarchical Bayesian parameter estimation methods are useful for enhancing statistical power, allowing for simultaneous estimation of individual subject parameters and the group distribution that they are drawn from, while also providing measures of uncertainty in these parameters in the posterior distribution. Here, we present a novel Python-based toolbox called HDDM (hierarchical drift diffusion model), which allows fast and flexible estimation of the the drift-diffusion model and the related linear ballistic accumulator model. HDDM requires fewer data per subject/condition than non-hierarchical methods, allows for full Bayesian data analysis, and can handle outliers in the data. Finally, HDDM supports the estimation of how trial-by-trial measurements (e.g., fMRI) influence decision-making parameters. This paper will first describe the theoretical background of the drift diffusion model and Bayesian inference. We then illustrate usage of the toolbox on a real-world data set from our lab. Finally, parameter recovery studies show that HDDM beats alternative fitting methods like the $\chi$(2)-quantile method as well as maximum likelihood estimation. The software and documentation can be downloaded at: http://ski.clps.brown.edu/hddm{\_}docs/},
author = {Wiecki, Thomas V and Sofer, Imri and Frank, Michael J},
doi = {10.3389/fninf.2013.00014},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wiecki, Sofer, Frank - 2013 - HDDM Hierarchical Bayesian estimation of the Drift-Diffusion Model in Python(3).pdf:pdf},
issn = {1662-5196},
journal = {Frontiers in neuroinformatics},
keywords = {Bayesian modeling,Python,bayesian modeling,decision-making,drift diffusion model,python,software},
pmid = {23935581},
title = {{HDDM: Hierarchical Bayesian estimation of the Drift-Diffusion Model in Python.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3731670{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2013}
}
@article{Wunderlich2012c,
abstract = {Decision making is often considered to arise out of contributions from a model-free habitual system and a model-based goal-directed system. Here, we investigated the effect of a dopamine manipulation on the degree to which either system contributes to instrumental behavior in a two-stage Markov decision task, which has been shown to discriminate model-free from model-based control. We found increased dopamine levels promote model-based over model-free choice.},
author = {Wunderlich, Klaus and Smittenaar, Peter and Dolan, Raymond J},
doi = {10.1016/j.neuron.2012.03.042},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wunderlich, Smittenaar, Dolan - 2012 - Dopamine enhances model-based over model-free choice behavior(2).pdf:pdf;:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wunderlich, Smittenaar, Dolan - 2012 - Dopamine enhances model-based over model-free choice behavior(3).pdf:pdf},
issn = {1097-4199},
journal = {Neuron},
keywords = {Benserazide,Benserazide: pharmacology,Brain,Brain: drug effects,Brain: physiology,Choice Behavior,Choice Behavior: drug effects,Choice Behavior: physiology,Dopamine,Dopamine Agents,Dopamine Agents: pharmacology,Dopamine: metabolism,Double-Blind Method,Humans,Male,Markov Chains,Models,Neurological,Theoretical,Young Adult},
month = {aug},
number = {3},
pages = {418--24},
pmid = {22884326},
title = {{Dopamine enhances model-based over model-free choice behavior.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3417237{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {75},
year = {2012}
}
@article{Zaghloul2012,
abstract = {The subthalamic nucleus (STN), which receives excitatory inputs from the cortex and has direct connections with the inhibitory pathways of the basal ganglia, is well positioned to efficiently mediate action selection. Here, we use microelectrode recordings captured during deep brain stimulation surgery as participants engage in a decision task to examine the role of the human STN in action selection. We demonstrate that spiking activity in the STN increases when participants engage in a decision and that the level of spiking activity increases with the degree of decision conflict. These data implicate the STN as an important mediator of action selection during decision processes.},
author = {Zaghloul, Kareem A and Weidemann, Christoph T and Lega, Bradley C and Jaggi, Jurg L and Baltuch, Gordon H and Kahana, Michael J},
doi = {10.1523/JNEUROSCI.5815-11.2012},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zaghloul et al. - 2012 - Neuronal activity in the human subthalamic nucleus encodes decision conflict during action selection.pdf:pdf},
isbn = {1529-2401 (Electronic)$\backslash$n0270-6474 (Linking)},
issn = {0270-6474},
journal = {Journal of Neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Aged,Conflict (Psychology),Decision Making,Decision Making: physiology,Deep Brain Stimulation,Deep Brain Stimulation: instrumentation,Deep Brain Stimulation: methods,Female,Humans,Learning,Learning: physiology,Male,Microelectrodes,Middle Aged,Neurons,Neurons: physiology,Subthalamic Nucleus,Subthalamic Nucleus: cytology,Subthalamic Nucleus: physiology},
month = {feb},
number = {7},
pages = {2453--2460},
pmid = {22396419},
title = {{Neuronal Activity in the Human Subthalamic Nucleus Encodes Decision Conflict during Action Selection}},
url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.5815-11.2012},
volume = {32},
year = {2012}
}
@article{Zhang2016,
abstract = {Progressive supranuclear palsy and Parkinson's disease have distinct underlying neuropathology, but both diseases affect cognitive function in addition to causing a movement disorder. They impair response inhibition and may lead to impulsivity, which can occur even in the presence of profound akinesia and rigidity. The current study examined the mechanisms of cognitive impairments underlying disinhibition, using horizontal saccadic latencies that obviate the impact of limb slowness on executing response decisions. Nineteen patients with clinically diagnosed progressive supranuclear palsy (Richardson's syndrome), 24 patients with clinically diagnosed Parkinson's disease and 26 healthy control subjects completed a saccadic Go/No-Go task with a head-mounted infrared saccadometer. Participants were cued on each trial to make a pro-saccade to a horizontal target or withhold their responses. Both patient groups had impaired behavioural performance, with more commission errors than controls. Mean saccadic latencies were similar between all three groups. We analysed behavioural responses as a binary decision between Go and No-Go choices. By using Bayesian parameter estimation, we fitted a hierarchical drift-diffusion model to individual participants' single trial data. The model decomposes saccadic latencies into parameters for the decision process: decision boundary, drift rate of accumulation, decision bias, and non-decision time. In a leave-one-out three-way classification analysis, the model parameters provided better discrimination between patients and controls than raw behavioural measures. Furthermore, the model revealed disease-specific deficits in the Go/No-Go decision process. Both patient groups had slower drift rate of accumulation, and shorter non-decision time than controls. But patients with progressive supranuclear palsy were strongly biased towards a pro-saccade decision boundary compared to Parkinson's patients and controls. This indicates a prepotency of responding in combination with a reduction in further accumulation of evidence, which provides a parsimonious explanation for the apparently paradoxical combination of disinhibition and severe akinesia. The combination of the well-tolerated oculomotor paradigm and the sensitivity of the model-based analysis provides a valuable approach for interrogating decision-making processes in neurodegenerative disorders. The mechanistic differences underlying participants' poor performance were not observable from classical analysis of behavioural data, but were clearly revealed by modelling. These differences provide a rational basis on which to develop and assess new therapeutic strategies for cognition and behaviour in these disorders.},
author = {Zhang, Jiaxiang and Rittman, Timothy and Nombela, Cristina and Fois, Alessandro and Coyle-Gilchrist, Ian and Barker, Roger A and Hughes, Laura E and Rowe, James B},
doi = {10.1093/brain/awv331},
file = {:C$\backslash$:/Users/BCS/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2016 - Different decision deficits impair response inhibition in progressive supranuclear palsy and Parkinson's disease.pdf:pdf},
isbn = {9781455748013},
issn = {14602156},
journal = {Brain},
keywords = {Bayesian hierarchical model,Drift-diffusion model,Parkinson's disease,Progressive supranuclear palsy,Saccadic inhibition},
number = {1},
pages = {161--173},
pmid = {26582559},
title = {{Different decision deficits impair response inhibition in progressive supranuclear palsy and Parkinson's disease}},
volume = {139},
year = {2016}
}
